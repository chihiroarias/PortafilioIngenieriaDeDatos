{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 4: EDA Multi-fuentes y Joins - Fill in the Blanks¬∂"
      ],
      "metadata": {
        "id": "GxwMkTvtVWbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Objetivos B√°sicos\n",
        "* Aprender a integrar datos de m√∫ltiples fuentes\n",
        "\n",
        "* Dominar los diferentes tipos de joins con pandas\n",
        "* Realizar an√°lisis agregados con groupby\n",
        "* Crear reportes consolidados de datos integrados"
      ],
      "metadata": {
        "id": "oVSgXIs3VkO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1: Setup Inicial: CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)"
      ],
      "metadata": {
        "id": "zk2-Afx_VxRq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LENg3xxfU8n0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194893cd-b901-4190-e8af-e8d4b7e9538f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup completo para an√°lisis multi-fuentes!\n"
          ]
        }
      ],
      "source": [
        "# Importar librer√≠as que vamos a usar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurar visualizaciones\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"‚úÖ Setup completo para an√°lisis multi-fuentes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2 Carga de Datos desde M√∫ltiples Fuentes\n"
      ],
      "metadata": {
        "id": "yGHmpRdDYejw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === CARGAR DATOS DE M√öLTIPLES FUENTES ===\n",
        "\n",
        "# 1. Cargar datos de viajes desde Parquet (Dataset oficial completo NYC)\n",
        "print(\"Cargando datos oficiales de NYC Taxi (dataset completo)...\")\n",
        "trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
        "\n",
        "# Cargar dataset oficial (~3M registros de enero 2023)\n",
        "trips = pd.read_parquet(trips_url)  # funci√≥n para leer archivos .parquet (m√°s eficiente que CSV) --read_parquet\n",
        "\n",
        "print(f\"   Viajes cargados: {trips.shape[0]:,} filas, {trips.shape[1]} columnas\")\n",
        "print(f\"   Columnas: {list(trips.columns)}\")\n",
        "print(f\"   Per√≠odo: {trips['tpep_pickup_datetime'].min()} a {trips['tpep_pickup_datetime'].max()}\")\n",
        "print(f\"   Tama√±o en memoria: {trips.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "# 2. Cargar datos de zonas desde CSV (Dataset oficial completo)\n",
        "print(\"\\nCargando datos oficiales de zonas NYC...\")\n",
        "zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
        "zones = pd.read_csv(zones_url)  # funci√≥n est√°ndar para archivos CSV --read_csv\n",
        "\n",
        "print(f\"   Zonas cargadas: {zones.shape[0]} filas, {zones.shape[1]} columnas\")\n",
        "print(f\"   Columnas: {list(zones.columns)}\")\n",
        "print(f\"   Boroughs √∫nicos: {zones['Borough'].unique()}\")\n",
        "\n",
        "# 3. Cargar calendario de eventos desde JSON\n",
        "print(\"\\nCargando datos de calendario de eventos...\")\n",
        "calendar_url = \"https://juanfkurucz.com/ucu-id/ut1/data/calendar.json\"\n",
        "calendar = pd.read_json(calendar_url)  # funci√≥n para archivos JSON --read_json\n",
        "calendar['date'] = pd.to_datetime(calendar['date']).dt.date  # convertir strings a fechas, luego extraer solo la fecha\n",
        "\n",
        "print(f\"   Eventos calendario: {calendar.shape[0]} filas\")\n",
        "print(f\"   Columnas: {list(calendar.columns)}\")\n",
        "\n",
        "# 4. Mostrar primeras filas de cada dataset\n",
        "print(\"\\nVISTA PREVIA DE DATOS:\")\n",
        "print(\"\\n--- TRIPS ---\")\n",
        "print(trips.head())  # m√©todo para mostrar primeras filas de un DataFrame --HEAD\n",
        "print(\"\\n--- ZONES ---\")\n",
        "print(zones.describe())  # mismo m√©todo para ver estructura de datos -- DESCRIBE\n",
        "print(\"\\n--- CALENDAR ---\")\n",
        "print(calendar.info())  # revisar formato de los eventos -- INFO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKR6idZqV68N",
        "outputId": "3851b6be-0ca4-4384-e29a-17650437d7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos oficiales de NYC Taxi (dataset completo)...\n",
            "   Viajes cargados: 3,066,766 filas, 19 columnas\n",
            "   Columnas: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
            "   Per√≠odo: 2008-12-31 23:01:42 a 2023-02-01 00:56:53\n",
            "   Tama√±o en memoria: 565.6 MB\n",
            "\n",
            "Cargando datos oficiales de zonas NYC...\n",
            "   Zonas cargadas: 265 filas, 4 columnas\n",
            "   Columnas: ['LocationID', 'Borough', 'Zone', 'service_zone']\n",
            "   Boroughs √∫nicos: ['EWR' 'Queens' 'Bronx' 'Manhattan' 'Staten Island' 'Brooklyn' 'Unknown'\n",
            " nan]\n",
            "\n",
            "Cargando datos de calendario de eventos...\n",
            "   Eventos calendario: 3 filas\n",
            "   Columnas: ['date', 'name', 'special']\n",
            "\n",
            "VISTA PREVIA DE DATOS:\n",
            "\n",
            "--- TRIPS ---\n",
            "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
            "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
            "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
            "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
            "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
            "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
            "\n",
            "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
            "0           0.97         1.0                  N           161           141   \n",
            "1           1.10         1.0                  N            43           237   \n",
            "2           2.51         1.0                  N            48           238   \n",
            "3           1.90         1.0                  N           138             7   \n",
            "4           1.43         1.0                  N           107            79   \n",
            "\n",
            "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
            "0             2          9.3   1.00      0.5        0.00           0.0   \n",
            "1             1          7.9   1.00      0.5        4.00           0.0   \n",
            "2             1         14.9   1.00      0.5       15.00           0.0   \n",
            "3             1         12.1   7.25      0.5        0.00           0.0   \n",
            "4             1         11.4   1.00      0.5        3.28           0.0   \n",
            "\n",
            "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
            "0                    1.0         14.30                   2.5         0.00  \n",
            "1                    1.0         16.90                   2.5         0.00  \n",
            "2                    1.0         34.90                   2.5         0.00  \n",
            "3                    1.0         20.85                   0.0         1.25  \n",
            "4                    1.0         19.68                   2.5         0.00  \n",
            "\n",
            "--- ZONES ---\n",
            "       LocationID\n",
            "count  265.000000\n",
            "mean   133.000000\n",
            "std     76.643112\n",
            "min      1.000000\n",
            "25%     67.000000\n",
            "50%    133.000000\n",
            "75%    199.000000\n",
            "max    265.000000\n",
            "\n",
            "--- CALENDAR ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   date     3 non-null      object\n",
            " 1   name     3 non-null      object\n",
            " 2   special  3 non-null      bool  \n",
            "dtypes: bool(1), object(2)\n",
            "memory usage: 183.0+ bytes\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Normalizaci√≥n de Datos"
      ],
      "metadata": {
        "id": "CFdMDqlka65d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === NORMALIZAR Y PREPARAR DATOS PARA JOINS ===\n",
        "\n",
        "# 1. Estandarizar nombres de columnas\n",
        "print(\"Normalizando nombres de columnas...\")\n",
        "trips.columns = trips.columns.str.lower()  # convertir todas las columnas a min√∫sculas\n",
        "zones.columns = zones.columns.str.lower()  # misma transformaci√≥n para consistencia\n",
        "\n",
        "print(f\"   Trips columnas: {list(trips.columns)}\")\n",
        "print(f\"   Zones columnas: {list(zones.columns)}\")\n",
        "\n",
        "# 2. Crear columna de fecha para el join con calendario\n",
        "trips['pickup_date'] = trips['tpep_pickup_datetime'].dt.date  # extraer solo la fecha (sin hora) de la columna datetime\n",
        "\n",
        "print(f\"   Columna pickup_date creada\")\n",
        "print(f\"   Rango de fechas: {trips['pickup_date'].min()} a {trips['pickup_date'].max()}\")\n",
        "\n",
        "# 3. Verificar tipos de datos para joins\n",
        "print(\"\\nVERIFICACI√ìN DE TIPOS PARA JOINS:\")\n",
        "print(f\"   trips['pulocationid'] tipo: {trips['pulocationid'].dtype}\")\n",
        "print(f\"   zones['locationid'] tipo: {zones['locationid'].dtype}\")\n",
        "print(f\"   trips['pickup_date'] tipo: {type(trips['pickup_date'].iloc[0])}\")\n",
        "print(f\"   calendar['date'] tipo: {type(calendar['date'].iloc[0])}\")\n",
        "\n",
        "# 4. Optimizaci√≥n para datasets grandes (~3M registros)\n",
        "print(\"\\nOPTIMIZACI√ìN PARA DATASETS GRANDES:\")\n",
        "initial_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
        "print(f\"   Memoria inicial: {initial_memory:.1f} MB\")\n",
        "\n",
        "# Optimizar tipos de datos para 3+ millones de registros\n",
        "print(\"   Optimizando tipos de datos para 3M+ registros...\")\n",
        "\n",
        "# Limpiar valores nulos antes de convertir tipos\n",
        "print(\"   Limpiando valores nulos antes de optimizaci√≥n...\")\n",
        "trips['passenger_count'] = trips['passenger_count'].fillna(0)  # m√©todo para rellenar valores nulos con un valor espec√≠fico\n",
        "trips = trips.dropna(subset=['pulocationid', 'dolocationid'])  # eliminar filas cr√≠ticas sin ubicaci√≥n (necesarias para joins)\n",
        "\n",
        "# Convertir tipos despu√©s de limpiar\n",
        "trips['pulocationid'] = trips['pulocationid'].astype('int16')\n",
        "trips['dolocationid'] = trips['dolocationid'].astype('int16')\n",
        "trips['passenger_count'] = trips['passenger_count'].astype('int8')\n",
        "zones['locationid'] = zones['locationid'].astype('int16')\n",
        "\n",
        "print(f\"   Registros despu√©s de limpieza: {len(trips):,}\")\n",
        "\n",
        "optimized_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
        "savings = ((initial_memory - optimized_memory) / initial_memory * 100)\n",
        "\n",
        "print(f\"   Memoria optimizada: {optimized_memory:.1f} MB\")\n",
        "print(f\"   Ahorro de memoria: {savings:.1f}%\")\n",
        "\n",
        "# 5. Revisar datos faltantes antes de joins\n",
        "print(\"\\nDATOS FALTANTES ANTES DE JOINS:\")\n",
        "print(\"Trips (top 5 columnas con m√°s nulos):\")\n",
        "trips_nulls = trips.isna().sum().sort_values(ascending=False).head()  # m√©todo para detectar valores nulos, sumar y ordenar\n",
        "print(trips_nulls)\n",
        "\n",
        "print(\"\\nZones:\")\n",
        "zones_nulls = zones.isna().sum()  # revisar si hay valores faltantes en lookup table\n",
        "print(zones_nulls)\n",
        "\n",
        "print(\"\\nCalendar:\")\n",
        "calendar_nulls = calendar.isna().sum()  # verificar integridad del calendario de eventos\n",
        "print(calendar_nulls)\n",
        "\n",
        "# An√°lisis de calidad de datos\n",
        "print(\"\\nAN√ÅLISIS DE CALIDAD:\")\n",
        "total_trips = len(trips)\n",
        "print(f\"   Total de viajes: {total_trips:,}\")\n",
        "print(f\"   Viajes sin pickup location: {trips['pulocationid'].isna().sum():,}\")\n",
        "print(f\"   Viajes sin dropoff location: {trips['dolocationid'].isna().sum():,}\")\n",
        "print(f\"   Viajes sin passenger_count: {trips['passenger_count'].isna().sum():,}\")\n",
        "\n",
        "# Estrategias de limpieza recomendadas\n",
        "print(\"\\nESTRATEGIAS DE LIMPIEZA:\")\n",
        "print(\"   Ubicaciones nulas: Eliminar (cr√≠tico para joins)\")\n",
        "print(\"   Passenger_count nulos: Rellenar con valor t√≠pico (1)\")\n",
        "print(\"   Tarifas nulas: Revisar caso por caso\")"
      ],
      "metadata": {
        "id": "V6xdep7gY0VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16058fc-70e1-40e9-90ef-ddb1080a6dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizando nombres de columnas...\n",
            "   Trips columnas: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
            "   Zones columnas: ['locationid', 'borough', 'zone', 'service_zone']\n",
            "   Columna pickup_date creada\n",
            "   Rango de fechas: 2008-12-31 a 2023-02-01\n",
            "\n",
            "VERIFICACI√ìN DE TIPOS PARA JOINS:\n",
            "   trips['pulocationid'] tipo: int64\n",
            "   zones['locationid'] tipo: int64\n",
            "   trips['pickup_date'] tipo: <class 'datetime.date'>\n",
            "   calendar['date'] tipo: <class 'datetime.date'>\n",
            "\n",
            "OPTIMIZACI√ìN PARA DATASETS GRANDES:\n",
            "   Memoria inicial: 682.6 MB\n",
            "   Optimizando tipos de datos para 3M+ registros...\n",
            "   Limpiando valores nulos antes de optimizaci√≥n...\n",
            "   Registros despu√©s de limpieza: 3,066,766\n",
            "   Memoria optimizada: 627.0 MB\n",
            "   Ahorro de memoria: 8.1%\n",
            "\n",
            "DATOS FALTANTES ANTES DE JOINS:\n",
            "Trips (top 5 columnas con m√°s nulos):\n",
            "airport_fee             71743\n",
            "congestion_surcharge    71743\n",
            "store_and_fwd_flag      71743\n",
            "ratecodeid              71743\n",
            "passenger_count             0\n",
            "dtype: int64\n",
            "\n",
            "Zones:\n",
            "locationid      0\n",
            "borough         1\n",
            "zone            1\n",
            "service_zone    2\n",
            "dtype: int64\n",
            "\n",
            "Calendar:\n",
            "date       0\n",
            "name       0\n",
            "special    0\n",
            "dtype: int64\n",
            "\n",
            "AN√ÅLISIS DE CALIDAD:\n",
            "   Total de viajes: 3,066,766\n",
            "   Viajes sin pickup location: 0\n",
            "   Viajes sin dropoff location: 0\n",
            "   Viajes sin passenger_count: 0\n",
            "\n",
            "ESTRATEGIAS DE LIMPIEZA:\n",
            "   Ubicaciones nulas: Eliminar (cr√≠tico para joins)\n",
            "   Passenger_count nulos: Rellenar con valor t√≠pico (1)\n",
            "   Tarifas nulas: Revisar caso por caso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paso 4. Join Principal - Trips con Zones"
      ],
      "metadata": {
        "id": "FvO-fxNoaCuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## === PRIMER JOIN: TRIPS + ZONES ===\n",
        "\n",
        "# 1. Hacer join de trips con zones para obtener informaci√≥n geogr√°fica\n",
        "print(\"Realizando join: trips + zones...\")\n",
        "trips_with_zones = trips.merge(zones,   # m√©todo principal para unir DataFrames\n",
        "                                left_on='pulocationid',   # columna de trips que contiene ID de zona de pickup\n",
        "                                right_on='locationid',  # columna de zones que contiene ID correspondiente\n",
        "                                how='left')       # tipo de join que mantiene todos los trips\n",
        "\n",
        "print(f\"   Registros antes del join: {len(trips)}\")\n",
        "print(f\"   Registros despu√©s del join: {len(trips_with_zones)}\")\n",
        "print(f\"   Nuevas columnas a√±adidas: {[col for col in trips_with_zones.columns if col not in trips.columns]}\")\n",
        "\n",
        "# 2. Verificar el resultado del join\n",
        "print(\"\\nVERIFICACI√ìN DEL JOIN:\")\n",
        "print(\"Conteo por Borough:\")\n",
        "print(trips_with_zones['borough'].value_counts())\n",
        "\n",
        "# 3. Verificar si hay valores nulos despu√©s del join\n",
        "null_after_join = trips_with_zones['borough'].isnull().sum()  # contar nulos en columna borough\n",
        "print(f\"\\nViajes sin borough asignado: {null_after_join}\")\n",
        "\n",
        "if null_after_join > 0:\n",
        "    print(\"   Algunos viajes no encontraron su zona correspondiente\")\n",
        "    print(\"   LocationIDs problem√°ticos:\")\n",
        "    problematic_ids = trips_with_zones[trips_with_zones['borough'].isnull()]['pulocationid'].unique()  # filtrar filas con nulos\n",
        "    print(f\"   {problematic_ids}\")\n",
        "\n",
        "# 4. Mostrar muestra del resultado\n",
        "print(\"\\nMUESTRA DEL DATASET INTEGRADO:\")\n",
        "print(trips_with_zones[['pulocationid', 'borough', 'zone', 'trip_distance', 'total_amount']].head())"
      ],
      "metadata": {
        "id": "eVKWWEIxaK0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f45cfd-9ec3-4b15-d9e9-24442c849483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Realizando join: trips + zones...\n",
            "   Registros antes del join: 3066766\n",
            "   Registros despu√©s del join: 3066766\n",
            "   Nuevas columnas a√±adidas: ['locationid', 'borough', 'zone', 'service_zone']\n",
            "\n",
            "VERIFICACI√ìN DEL JOIN:\n",
            "Conteo por Borough:\n",
            "borough\n",
            "Manhattan        2715369\n",
            "Queens            286645\n",
            "Unknown            40116\n",
            "Brooklyn           18076\n",
            "Bronx               4162\n",
            "EWR                  410\n",
            "Staten Island        341\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Viajes sin borough asignado: 1647\n",
            "   Algunos viajes no encontraron su zona correspondiente\n",
            "   LocationIDs problem√°ticos:\n",
            "   [265]\n",
            "\n",
            "MUESTRA DEL DATASET INTEGRADO:\n",
            "   pulocationid    borough               zone  trip_distance  total_amount\n",
            "0           161  Manhattan     Midtown Center           0.97         14.30\n",
            "1            43  Manhattan       Central Park           1.10         16.90\n",
            "2            48  Manhattan       Clinton East           2.51         34.90\n",
            "3           138     Queens  LaGuardia Airport           1.90         20.85\n",
            "4           107  Manhattan           Gramercy           1.43         19.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 5: Segundo Join - Agregar Datos de *Calendario*"
      ],
      "metadata": {
        "id": "JsBPWOktbtiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === SEGUNDO JOIN: TRIPS_ZONES + CALENDAR ===\n",
        "\n",
        "# 1. Hacer join con datos de calendario\n",
        "print(\"Realizando join: trips_zones + calendar...\")\n",
        "trips_complete = trips_with_zones.merge(calendar,   # mismo m√©todo de join que antes\n",
        "                                         left_on='pickup_date',   # columna de fecha que creamos en trips\n",
        "                                         right_on='date',  # columna de fecha en calendar\n",
        "                                         how='left')       # tipo que mantiene todos los trips aunque no haya evento especial\n",
        "\n",
        "print(f\"   Registros antes del join: {len(trips_with_zones)}\")\n",
        "print(f\"   Registros despu√©s del join: {len(trips_complete)}\")\n",
        "\n",
        "# 2. Crear flag de evento especial\n",
        "trips_complete['is_special_day'] = trips_complete['special'].fillna('False')  # m√©todo para rellenar nulos con valor por defecto\n",
        "\n",
        "print(\"\\nDISTRIBUCI√ìN DE D√çAS ESPECIALES:\")\n",
        "print(trips_complete['is_special_day'].value_counts())\n",
        "print(\"\\nEjemplos de eventos especiales:\")\n",
        "special_days = trips_complete[trips_complete['is_special_day'] == True]\n",
        "if len(special_days) > 0:\n",
        "    print(special_days[['pickup_date', 'special', 'borough']].drop_duplicates())\n",
        "else:\n",
        "    print(\"   No hay eventos especiales en este per√≠odo\")\n",
        "\n",
        "# 3. Mostrar dataset final integrado\n",
        "print(\"\\nDATASET FINAL INTEGRADO:\")\n",
        "print(f\"   Total registros: {len(trips_complete)}\")\n",
        "print(f\"   Total columnas: {len(trips_complete.columns)}\")\n",
        "print(f\"   Columnas principales: {['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']}\")\n",
        "\n",
        "# 4. Verificar integridad de los datos finales\n",
        "print(\"\\nVERIFICACI√ìN FINAL:\")\n",
        "print(\"Datos faltantes por columna clave:\")\n",
        "key_columns = ['borough', 'zone', 'trip_distance', 'total_amount', 'is_special_day']\n",
        "for col in key_columns:\n",
        "    missing = trips_complete[col].isna().sum()  # verificar nulos en cada columna clave final\n",
        "    print(f\"   {col}: {missing} nulos\")"
      ],
      "metadata": {
        "id": "U6Xr-e23bzF1",
        "outputId": "ee40d725-b7bf-4d6e-9793-f4baf744ded6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Realizando join: trips_zones + calendar...\n",
            "   Registros antes del join: 3066766\n",
            "   Registros despu√©s del join: 3066766\n",
            "\n",
            "DISTRIBUCI√ìN DE D√çAS ESPECIALES:\n",
            "is_special_day\n",
            "False    3066766\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Ejemplos de eventos especiales:\n",
            "   No hay eventos especiales en este per√≠odo\n",
            "\n",
            "DATASET FINAL INTEGRADO:\n",
            "   Total registros: 3066766\n",
            "   Total columnas: 28\n",
            "   Columnas principales: ['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']\n",
            "\n",
            "VERIFICACI√ìN FINAL:\n",
            "Datos faltantes por columna clave:\n",
            "   borough: 1647 nulos\n",
            "   zone: 40116 nulos\n",
            "   trip_distance: 0 nulos\n",
            "   total_amount: 0 nulos\n",
            "   is_special_day: 0 nulos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 6: Analisis por Borough"
      ],
      "metadata": {
        "id": "4JkOPRZVcBUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === AN√ÅLISIS AGREGADO POR BOROUGH ===\n",
        "\n",
        "# 1. An√°lisis b√°sico por borough (con dataset grande)\n",
        "print(\"An√°lisis por Borough (procesando datos grandes)...\")\n",
        "borough_analysis = trips_complete.groupby(by='borough').agg({   # m√©todo para agrupar datos, por qu√© columna geogr√°fica?\n",
        "    'pulocationid': 'count',  # funci√≥n para contar n√∫mero de registros/viajes\n",
        "    'trip_distance': ['mean', 'std', 'median'],  # funci√≥n para promedio + desviaci√≥n + mediana\n",
        "    'total_amount': ['mean', 'std', 'median'],   # mismas estad√≠sticas para tarifas\n",
        "    'fare_amount': 'mean',     # solo promedio de tarifa base\n",
        "    'tip_amount': ['mean', 'median'],  # estad√≠sticas de propinas\n",
        "    'passenger_count': 'mean'  # funci√≥n para promedio de pasajeros\n",
        "}).round(2)\n",
        "\n",
        "# Aplanar columnas multi-nivel\n",
        "borough_analysis.columns = ['num_trips', 'avg_distance', 'std_distance', 'median_distance',\n",
        "                           'avg_total', 'std_total', 'median_total', 'avg_fare',\n",
        "                           'avg_tip', 'median_tip', 'avg_passengers']\n",
        "\n",
        "# Ordenar por n√∫mero de viajes\n",
        "borough_analysis = borough_analysis.sort_values(by='num_trips', ascending=False)  # m√©todo para ordenar DataFrame por una columna espec√≠fica\n",
        "\n",
        "print(\"\\nAN√ÅLISIS COMPLETO POR BOROUGH:\")\n",
        "print(borough_analysis)\n",
        "\n",
        "# 2. Calcular m√©tricas adicionales empresariales\n",
        "borough_analysis['revenue_per_km'] = (borough_analysis['avg_total'] /\n",
        "                                     borough_analysis['avg_distance']).round(2)\n",
        "borough_analysis['tip_rate'] = (borough_analysis['avg_tip'] /\n",
        "                               borough_analysis['avg_fare'] * 100).round(1)\n",
        "borough_analysis['market_share'] = (borough_analysis['num_trips'] /\n",
        "                                  borough_analysis['num_trips'].sum() * 100).round(1)\n",
        "\n",
        "print(\"\\nAN√ÅLISIS CON M√âTRICAS EMPRESARIALES:\")\n",
        "print(borough_analysis[['num_trips', 'market_share', 'revenue_per_km', 'tip_rate']])\n",
        "\n",
        "# 3. Encontrar insights\n",
        "print(\"\\nINSIGHTS PRINCIPALES:\")\n",
        "print(f\"   Borough con m√°s viajes: {borough_analysis.index[0]}\")\n",
        "print(f\"   Borough con viajes m√°s largos: {borough_analysis['avg_distance'].idxmax()}\")\n",
        "print(f\"   Borough con tarifas m√°s altas: {borough_analysis['avg_total'].idxmax()}\")\n",
        "print(f\"   Mejor revenue por km: {borough_analysis['revenue_per_km'].idxmax()}\")"
      ],
      "metadata": {
        "id": "h4hTs-g1cFeD",
        "outputId": "149915c4-c7d3-41e3-a91d-37cc672f263d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An√°lisis por Borough (procesando datos grandes)...\n",
            "\n",
            "AN√ÅLISIS COMPLETO POR BOROUGH:\n",
            "               num_trips  avg_distance  std_distance  median_distance  \\\n",
            "borough                                                                 \n",
            "Manhattan        2715369          2.88        264.53             1.63   \n",
            "Queens            286645         12.32         14.42            11.24   \n",
            "Unknown            40116          7.57        144.96             2.64   \n",
            "Brooklyn           18076          5.68         70.86             3.45   \n",
            "Bronx               4162          5.30          6.34             3.10   \n",
            "EWR                  410          1.59          5.68             0.00   \n",
            "Staten Island        341         11.36         10.21            14.80   \n",
            "\n",
            "               avg_total  std_total  median_total  avg_fare  avg_tip  \\\n",
            "borough                                                                \n",
            "Manhattan          22.49      14.54         19.25     14.78     2.88   \n",
            "Queens             67.27      33.64         70.35     49.98     7.85   \n",
            "Unknown            38.08      30.41         25.38     26.44     4.82   \n",
            "Brooklyn           33.02      22.56         28.64     26.81     2.94   \n",
            "Bronx              34.54      33.26         29.70     30.24     0.78   \n",
            "EWR               104.38      62.75        118.55     87.99    12.44   \n",
            "Staten Island      62.53      44.92         67.80     48.74     1.32   \n",
            "\n",
            "               median_tip  avg_passengers  \n",
            "borough                                    \n",
            "Manhattan            2.66            1.33  \n",
            "Queens               8.18            1.38  \n",
            "Unknown              3.14            1.34  \n",
            "Brooklyn             0.60            1.08  \n",
            "Bronx                0.00            1.03  \n",
            "EWR                 10.00            1.58  \n",
            "Staten Island        0.00            1.12  \n",
            "\n",
            "AN√ÅLISIS CON M√âTRICAS EMPRESARIALES:\n",
            "               num_trips  market_share  revenue_per_km  tip_rate\n",
            "borough                                                         \n",
            "Manhattan        2715369          88.6            7.81      19.5\n",
            "Queens            286645           9.4            5.46      15.7\n",
            "Unknown            40116           1.3            5.03      18.2\n",
            "Brooklyn           18076           0.6            5.81      11.0\n",
            "Bronx               4162           0.1            6.52       2.6\n",
            "EWR                  410           0.0           65.65      14.1\n",
            "Staten Island        341           0.0            5.50       2.7\n",
            "\n",
            "INSIGHTS PRINCIPALES:\n",
            "   Borough con m√°s viajes: Manhattan\n",
            "   Borough con viajes m√°s largos: Queens\n",
            "   Borough con tarifas m√°s altas: EWR\n",
            "   Mejor revenue por km: EWR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 7: Analisis por Borough y Dia especial"
      ],
      "metadata": {
        "id": "xiWBrvPydSdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === AN√ÅLISIS COMPARATIVO: D√çAS NORMALES VS ESPECIALES ===\n",
        "\n",
        "# 1. An√°lisis por borough y tipo de d√≠a\n",
        "print(\"üìÖ An√°lisis: Borough + D√≠a Especial...\")\n",
        "borough_day_analysis = trips_complete.groupby(by=['borough', 'is_special_day']).agg({  # agrupar por DOS columnas: geograf√≠a y tipo de d√≠a\n",
        "    'pulocationid': 'count',  # funci√≥n para contar viajes\n",
        "    'trip_distance': 'mean',  # funci√≥n para promedio de distancia\n",
        "    'total_amount': 'mean'    # funci√≥n para promedio de tarifa\n",
        "}).round(2)\n",
        "\n",
        "borough_day_analysis.columns = ['num_trips', 'avg_distance', 'avg_total']\n",
        "\n",
        "print(\"\\nüìä AN√ÅLISIS BOROUGH + D√çA ESPECIAL:\")\n",
        "print(borough_day_analysis)\n",
        "\n",
        "# 2. Comparar d√≠as normales vs especiales\n",
        "print(\"\\nüîç COMPARACI√ìN D√çAS NORMALES VS ESPECIALES:\")\n",
        "\n",
        "# Pivotear para comparar f√°cilmente\n",
        "comparison = trips_complete.groupby(by='is_special_day').agg({  # agrupar solo por tipo de d√≠a para comparaci√≥n general\n",
        "    'trip_distance': 'mean',    # promedio de distancia por tipo de d√≠a\n",
        "    'total_amount': 'mean',     # promedio de tarifa por tipo de d√≠a\n",
        "    'pulocationid': 'count'     # conteo de viajes por tipo de d√≠a\n",
        "}).round(2)\n",
        "\n",
        "# Renombrar √≠ndices seg√∫n los valores √∫nicos encontrados\n",
        "unique_day_types = comparison.index.tolist()\n",
        "if len(unique_day_types) == 2:\n",
        "    comparison.index = ['D√≠a Normal', 'D√≠a Especial']\n",
        "elif len(unique_day_types) == 1:\n",
        "    if unique_day_types[0] in ['False', False]:\n",
        "        comparison.index = ['D√≠a Normal']\n",
        "    else:\n",
        "        comparison.index = ['D√≠a Especial']\n",
        "\n",
        "comparison.columns = ['Avg Distance', 'Avg Amount', 'Num Trips']\n",
        "\n",
        "print(comparison)\n",
        "\n",
        "# 3. Calcular diferencias porcentuales\n",
        "if len(comparison) > 1:\n",
        "    # Hay tanto d√≠as normales como especiales\n",
        "    if 'D√≠a Normal' in comparison.index and 'D√≠a Especial' in comparison.index:\n",
        "        normal_day = comparison.loc['D√≠a Normal']\n",
        "        special_day = comparison.loc['D√≠a Especial']\n",
        "\n",
        "        print(\"\\nIMPACTO DE D√çAS ESPECIALES:\")\n",
        "        distance_change = ((special_day['Avg Distance'] - normal_day['Avg Distance']) / normal_day['Avg Distance'] * 100)\n",
        "        amount_change = ((special_day['Avg Amount'] - normal_day['Avg Amount']) / normal_day['Avg Amount'] * 100)\n",
        "\n",
        "        print(f\"   Cambio en distancia promedio: {distance_change:+.1f}%\")\n",
        "        print(f\"   Cambio en tarifa promedio: {amount_change:+.1f}%\")\n",
        "    else:\n",
        "        print(\"\\nINFORMACI√ìN DE D√çAS:\")\n",
        "        for idx, row in comparison.iterrows():\n",
        "            print(f\"   {idx}: {row['Num Trips']:,} viajes, ${row['Avg Amount']:.2f} promedio\")\n",
        "else:\n",
        "    print(f\"\\nSOLO HAY {comparison.index[0]}:\")\n",
        "    print(f\"   Viajes: {comparison.iloc[0]['Num Trips']:,}\")\n",
        "    print(f\"   Distancia promedio: {comparison.iloc[0]['Avg Distance']:.2f} millas\")\n",
        "    print(f\"   Tarifa promedio: ${comparison.iloc[0]['Avg Amount']:.2f}\")\n",
        "    print(\"   No hay datos de d√≠as especiales para comparar en este per√≠odo\")"
      ],
      "metadata": {
        "id": "f94aCpfAdhGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12b2dd4-8f81-4162-d2f0-843d64fc0e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ An√°lisis: Borough + D√≠a Especial...\n",
            "\n",
            "üìä AN√ÅLISIS BOROUGH + D√çA ESPECIAL:\n",
            "                              num_trips  avg_distance  avg_total\n",
            "borough       is_special_day                                    \n",
            "Bronx         False                4162          5.30      34.54\n",
            "Brooklyn      False               18076          5.68      33.02\n",
            "EWR           False                 410          1.59     104.38\n",
            "Manhattan     False             2715369          2.88      22.49\n",
            "Queens        False              286645         12.32      67.27\n",
            "Staten Island False                 341         11.36      62.53\n",
            "Unknown       False               40116          7.57      38.08\n",
            "\n",
            "üîç COMPARACI√ìN D√çAS NORMALES VS ESPECIALES:\n",
            "            Avg Distance  Avg Amount  Num Trips\n",
            "D√≠a Normal          3.85       27.02    3066766\n",
            "\n",
            "SOLO HAY D√≠a Normal:\n",
            "   Viajes: 3,066,766.0\n",
            "   Distancia promedio: 3.85 millas\n",
            "   Tarifa promedio: $27.02\n",
            "   No hay datos de d√≠as especiales para comparar en este per√≠odo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 8: T√©cnicas para Datasets Grandes"
      ],
      "metadata": {
        "id": "i67wz1gFeR4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === T√âCNICAS PARA TRABAJAR CON DATASETS GRANDES ===\n",
        "\n",
        "# 1. Sampling estrat√©gico para visualizaciones\n",
        "print(\"‚ö° Aplicando t√©cnicas para datasets grandes...\")\n",
        "\n",
        "# Si el dataset es muy grande, usar muestra para visualizaciones\n",
        "if len(trips_complete) > 50000:\n",
        "    print(f\"   üìä Dataset grande detectado: {len(trips_complete):,} registros\")\n",
        "    print(\"   üéØ Creando muestra estratificada para visualizaciones...\")\n",
        "\n",
        "    # Muestra proporcional por borough (simple aleatoria aqu√≠)\n",
        "    sample_size = min(10000, len(trips_complete) // 10)\n",
        "    trips_sample = trips_complete.sample(n=sample_size, random_state=42)  # m√©todo para tomar muestra aleatoria de n registros\n",
        "\n",
        "    print(f\"   ‚úÖ Muestra creada: {len(trips_sample):,} registros ({len(trips_sample)/len(trips_complete)*100:.1f}%)\")\n",
        "else:\n",
        "    trips_sample = trips_complete\n",
        "    print(\"   ‚ÑπÔ∏è Dataset peque√±o, usando datos completos para visualizaci√≥n\")\n",
        "\n",
        "# 2. An√°lisis de performance de joins\n",
        "print(\"\\nüìà AN√ÅLISIS DE PERFORMANCE:\")\n",
        "join_stats = {\n",
        "    'total_trips': len(trips),\n",
        "    'matched_zones': (trips_complete['borough'].notna()).sum(),\n",
        "    'match_rate': (trips_complete['borough'].notna().sum() / len(trips) * 100),\n",
        "    'unique_zones_used': trips_complete['zone'].nunique(),\n",
        "    'total_zones_available': len(zones),\n",
        "    'zone_coverage': (trips_complete['zone'].nunique() / len(zones) * 100)\n",
        "}\n",
        "\n",
        "for key, value in join_stats.items():\n",
        "    if 'rate' in key or 'coverage' in key:\n",
        "        print(f\"   {key}: {value:.1f}%\")\n",
        "    else:\n",
        "        print(f\"   {key}: {value:,}\")\n",
        "\n",
        "# 3. An√°lisis temporal avanzado (solo si hay suficientes datos)\n",
        "if len(trips_complete) > 1000:\n",
        "    print(\"\\nüìÖ AN√ÅLISIS TEMPORAL AVANZADO:\")\n",
        "\n",
        "    # An√°lisis por hora del d√≠a\n",
        "    trips_complete['pickup_hour'] = trips_complete['tpep_pickup_datetime'].dt.hour  # extraer hora de la fecha/hora\n",
        "    hourly_analysis = trips_complete.groupby(by='pickup_hour').agg({  # agrupar por hora del d√≠a\n",
        "        'pulocationid': 'count',     # contar viajes por hora (en min√∫sculas tras .str.lower())\n",
        "        'total_amount': 'mean',      # tarifa promedio por hora\n",
        "        'trip_distance': 'mean'      # distancia promedio por hora\n",
        "    }).round(2)\n",
        "\n",
        "    hourly_analysis.columns = ['trips_count', 'avg_amount', 'avg_distance']\n",
        "\n",
        "    print(\"   ‚è∞ Horas pico por n√∫mero de viajes:\")\n",
        "    peak_hours = hourly_analysis.sort_values(by='trips_count', ascending=False).head(3)  # ordenar por m√°s viajes, tomar top 3\n",
        "    for hour, stats in peak_hours.iterrows():\n",
        "        print(f\"      {hour:02d}:00 - {stats['trips_count']:,} viajes\")"
      ],
      "metadata": {
        "id": "e3UGHBqpe_-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee592af-9de3-422d-cb39-67d8a533a29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Aplicando t√©cnicas para datasets grandes...\n",
            "   üìä Dataset grande detectado: 3,066,766 registros\n",
            "   üéØ Creando muestra estratificada para visualizaciones...\n",
            "   ‚úÖ Muestra creada: 10,000 registros (0.3%)\n",
            "\n",
            "üìà AN√ÅLISIS DE PERFORMANCE:\n",
            "   total_trips: 3,066,766\n",
            "   matched_zones: 3,065,119\n",
            "   match_rate: 99.9%\n",
            "   unique_zones_used: 255\n",
            "   total_zones_available: 265\n",
            "   zone_coverage: 96.2%\n",
            "\n",
            "üìÖ AN√ÅLISIS TEMPORAL AVANZADO:\n",
            "   ‚è∞ Horas pico por n√∫mero de viajes:\n",
            "      18:00 - 215,889.0 viajes\n",
            "      17:00 - 209,493.0 viajes\n",
            "      15:00 - 196,424.0 viajes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 9: Analisis de Correlaciones"
      ],
      "metadata": {
        "id": "49pCdplmenuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === AN√ÅLISIS DE CORRELACIONES NUM√âRICAS ===\n",
        "\n",
        "# Calcular correlaciones entre variables num√©ricas\n",
        "print(\"Calculando correlaciones entre variables num√©ricas...\")\n",
        "numeric_cols = ['trip_distance', 'total_amount', 'fare_amount', 'tip_amount']\n",
        "corr_matrix = trips_complete[numeric_cols].corr()  # m√©todo para calcular matriz de correlaci√≥n\n",
        "\n",
        "print(\"\\nMatriz de Correlaci√≥n:\")\n",
        "print(corr_matrix.round(3))\n",
        "\n",
        "print(\"\\nCorrelaciones m√°s fuertes:\")\n",
        "corr_pairs = []\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "        corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
        "\n",
        "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
        "for var1, var2, corr in corr_pairs[:3]:\n",
        "    print(f\"   {var1} vs {var2}: {corr:.3f}\")\n",
        "\n",
        "print(\"\\nINTERPRETACI√ìN DE CORRELACIONES:\")\n",
        "print(\"   > 0.7: Correlaci√≥n fuerte positiva\")\n",
        "print(\"   0.3-0.7: Correlaci√≥n moderada positiva\")\n",
        "print(\"   -0.3-0.3: Correlaci√≥n d√©bil\")\n",
        "print(\"   < -0.7: Correlaci√≥n fuerte negativa\")"
      ],
      "metadata": {
        "id": "iZSIOG1FdrTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b7fed3-57fb-4361-cc4f-e8bde8d808bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando correlaciones entre variables num√©ricas...\n",
            "\n",
            "Matriz de Correlaci√≥n:\n",
            "               trip_distance  total_amount  fare_amount  tip_amount\n",
            "trip_distance          1.000         0.016        0.016       0.011\n",
            "total_amount           0.016         1.000        0.980       0.710\n",
            "fare_amount            0.016         0.980        1.000       0.590\n",
            "tip_amount             0.011         0.710        0.590       1.000\n",
            "\n",
            "Correlaciones m√°s fuertes:\n",
            "   total_amount vs fare_amount: 0.980\n",
            "   total_amount vs tip_amount: 0.710\n",
            "   fare_amount vs tip_amount: 0.590\n",
            "\n",
            "INTERPRETACI√ìN DE CORRELACIONES:\n",
            "   > 0.7: Correlaci√≥n fuerte positiva\n",
            "   0.3-0.7: Correlaci√≥n moderada positiva\n",
            "   -0.3-0.3: Correlaci√≥n d√©bil\n",
            "   < -0.7: Correlaci√≥n fuerte negativa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Responde estas preguntas despu√©s de completar el c√≥digo:\n",
        "\n",
        "1. ¬øQu√© diferencia hay entre un LEFT JOIN y un INNER JOIN?  \n",
        "Un left join\n",
        "\n",
        "2. ¬øPor qu√© usamos LEFT JOIN en lugar de INNER JOIN para trips+zones?  \n",
        "\n",
        "3. ¬øQu√© problemas pueden surgir al hacer joins con datos de fechas?  \n",
        "\n",
        "4. ¬øCu√°l es la ventaja de integrar m√∫ltiples fuentes de datos?  \n",
        "\n",
        "5. ¬øQu√© insights de negocio obtuviste del an√°lisis integrado?  \n"
      ],
      "metadata": {
        "id": "peTazWt9kXim"
      }
    }
  ]
}