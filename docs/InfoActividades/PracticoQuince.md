---
title: "UT5 - Actividad 15 - Pipelines ETL, DataOps y Orquestaci√≥n con Prefect"
date: 2025-11-29
---

# UT5 - Actividad 15: Pipelines ETL, DataOps y Orquestaci√≥n con Prefect

## Contexto

Dise√±o e implementaci√≥n de un mini pipeline ETL con Prefect, explorando conceptos fundamentales de orquestaci√≥n de datos y funcionalidades avanzadas del orquestador. El trabajo abarca desde la creaci√≥n de tasks y flows b√°sicos hasta la implementaci√≥n de caracter√≠sticas como retries, caching, logging estructurado, concurrencia, y deployments.

## Objetivos

- Comprender conceptos fundamentales de Prefect: Tasks, Flows, States y DAG impl√≠cito
- Implementar pipelines ETL con Tasks decoradas para Extract, Transform y Load
- Explorar funcionalidades avanzadas: retries, caching, logging personalizado y concurrencia
- Aplicar Task Runners para procesamiento paralelo de datos
- Investigar Deployments y Scheduling para automatizaci√≥n de pipelines
- Conectar conceptos de orquestaci√≥n con principios de DataOps

## Datos

- **Escenario**: Ventas diarias de una cadena de tiendas minoristas
- **Dataset sint√©tico generado**:
  - 100 registros de transacciones
  - Campos: fecha, producto, cantidad, precio_unitario, region
  - Regiones: Norte, Sur, Este, Oeste
  - Productos: A, B, C, D
- **Tipo de pipeline**: Batch (procesamiento diario)
- **Justificaci√≥n**: Datos consolidados al final del d√≠a, decisiones estrat√©gicas basadas en an√°lisis de tendencias diarias/semanales

## Metodolog√≠a

### 1. Investigaci√≥n de Conceptos Fundamentales

**Tasks en Prefect:**

- Unidad de trabajo individual dentro de un flujo de datos
- Creadas con el decorador `@task` sobre funciones Python
- Permiten observabilidad granular, reintentos autom√°ticos, y cache de resultados
- Evaluaci√≥n perezosa ("lazily evaluated"): construcci√≥n de grafo de dependencias antes de ejecuci√≥n
- Estados principales: Pending, Running, Completed, Failed
- Par√°metros clave: `retries`, `cache_expiration`, `timeout_seconds`

**Flows en Prefect:**

- Contenedor principal que orquesta la ejecuci√≥n de m√∫ltiples tasks
- Define el pipeline completo con manejo de estado, logging y scheduling
- Soporte para subflows: flows anidados para modularidad y reutilizaci√≥n
- DAG impl√≠cito: Prefect infiere dependencias del flujo de datos en el c√≥digo
- Permite control de flujo nativo de Python (if/else, loops)

**Result Persistence y Caching:**

- Almacenamiento autom√°tico de resultados en storage persistente
- Permite recuperaci√≥n sin re-ejecuci√≥n, debugging, y recuperaci√≥n desde puntos de fallo
- Cache basado en hash de inputs de la task
- `cache_expiration`: duraci√≥n de validez del resultado cacheado
- `cache_key_fn`: funci√≥n personalizada para generaci√≥n de cache key

### 2. Implementaci√≥n del Pipeline Base

**Pipeline ETL est√°ndar:**

1. **Extract**: Generaci√≥n de datos sint√©ticos de ventas

   - 100 registros con fecha, producto, cantidad, precio, regi√≥n
   - Uso de numpy y pandas para creaci√≥n de dataset

2. **Transform**: Aplicaci√≥n de transformaciones

   - C√°lculo de total de venta (`cantidad * precio_unitario`)
   - Categorizaci√≥n de ticket size (small, medium, large)
   - Logging de estad√≠sticas procesadas

3. **Load**: Almacenamiento de datos procesados
   - Exportaci√≥n a CSV
   - Confirmaci√≥n de registros guardados

**Orquestaci√≥n con Flow:**

- Flow principal que ejecuta tasks en secuencia
- Paso de datos entre tasks mediante return values
- Inferencia autom√°tica de dependencias por Prefect

### 3. Funcionalidades Avanzadas Implementadas

**A. Retries y Manejo de Errores:**

- Task con reintentos autom√°ticos: `retries=3, retry_delay_seconds=10`
- Simulaci√≥n de fallos aleatorios para probar robustez
- Exponential backoff: tiempo de espera aumenta exponencialmente entre reintentos
- √ötil para recursos temporalmente no disponibles (API rate limits, DB ocupada)

**B. Caching de Resultados:**

- Task de extracci√≥n con cache: `cache_expiration=timedelta(minutes=30)`
- Previene re-ejecuci√≥n de operaciones costosas con mismos inputs
- Invalidaci√≥n autom√°tica cuando inputs cambian
- Casos de uso: APIs que actualizan una vez al d√≠a, transformaciones ML costosas

**C. Logging Estructurado:**

- Uso de `get_run_logger()` para logging integrado con Prefect
- Niveles: DEBUG, INFO, WARNING, ERROR
- Logging de validaciones de calidad de datos
- Mensajes estructurados asociados con task runs espec√≠ficas
- Configuraci√≥n de nivel v√≠a `PREFECT_LOGGING_LEVEL`

**D. Concurrencia y Paralelismo:**

- `ConcurrentTaskRunner` para ejecuci√≥n paralela con threads
- Procesamiento paralelo por regi√≥n usando `.submit()`
- `PrefectFuture` para manejo as√≠ncrono de resultados
- √ötil para tasks I/O-bound (llamadas a APIs, lectura/escritura)
- Alternativas: `DaskTaskRunner` para procesamiento distribuido CPU-intensive

### 4. Deployments y Scheduling (Conceptual)

**Deployments:**

- Configuraci√≥n para ejecutar Flow en entorno espec√≠fico con schedule
- Empaqueta Flow con metadatos: infraestructura, timing, par√°metros
- Diferencia con Flow: permite orquestaci√≥n programada y ejecuci√≥n remota

**Work Pools y Workers:**

- **Work Pool**: grupo l√≥gico de infraestructura donde se ejecutan deployments
- **Worker**: proceso que escucha por trabajo y ejecuta flow runs
- Relaci√≥n: Work Pool ‚Üí Worker ‚Üí Flow Run

**Scheduling:**

- **CronSchedule**: sintaxis cron est√°ndar (`"0 6 * * *"` para diario 6 AM)
- **IntervalSchedule**: ejecuci√≥n cada X tiempo desde punto inicio
- **RRuleSchedule**: especificaci√≥n iCalendar RFC para reglas complejas
- Preferir RRule sobre cron para l√≥gica de calendario compleja

### 5. Extensiones DataOps Implementadas

**Pipeline Parametrizado con Caching:**

```python
@flow
def etl_flow_parametrized(min_amount: float = 0.0, output_path: str = "output.csv", n_rows: int = 100)
```

- Par√°metros configurables: n√∫mero de registros, filtros, rutas de salida
- Cache invalidado autom√°ticamente al cambiar par√°metros
- Filtrado din√°mico por monto m√≠nimo
- Flexibilidad para diferentes casos de uso

**Pipeline Concurrente:**

```python
@flow(task_runner=ConcurrentTaskRunner())
def etl_flow_concurrent()
```

- Procesamiento paralelo de cuatro regiones simult√°neamente
- Uso de `.submit()` para ejecuci√≥n as√≠ncrona
- Recolecci√≥n de resultados con `.result()`
- Reducci√≥n de tiempo de ejecuci√≥n para datasets grandes

**Validaci√≥n con Logging:**

```python
@task(retries=2, retry_delay_seconds=5)
def validate_data(df: pd.DataFrame)
```

- Validaciones de calidad: DataFrame vac√≠o, valores nulos
- Logging estructurado de errores y warnings
- Reintentos autom√°ticos en caso de fallo de validaci√≥n
- Lanzamiento de excepciones para detener pipeline si datos inv√°lidos

## Resultados

### Ejecuci√≥n del Pipeline Base

**Logs de Prefect observados:**

```
12:45:30.123 | INFO | Flow run 'etl_flow' - Created flow run
12:45:30.456 | INFO | Flow run 'etl_flow' - Executing 'extract_data'
12:45:30.789 | INFO | Task run 'extract_data' - üì• Extra√≠dos 100 registros
12:45:31.012 | INFO | Task run 'extract_data' - Finished in state Completed()
12:45:31.234 | INFO | Flow run 'etl_flow' - Executing 'transform_data'
12:45:31.456 | INFO | Task run 'transform_data' - üîÑ Transformados 100 registros
12:45:31.678 | INFO | Task run 'transform_data' - Finished in state Completed()
```

**Caracter√≠sticas observadas:**

- Timestamps precisos para tracking temporal
- Estados de tasks: Pending ‚Üí Running ‚Üí Completed
- Distinci√≥n entre "Flow run" (orquestador) y "Task run" (tasks individuales)
- Orden de ejecuci√≥n inferido autom√°ticamente del flujo de datos
- Logs autom√°ticos sin instrumentaci√≥n manual

### Pipeline Concurrente

**Resultados por regi√≥n procesados en paralelo:**

```python
[
    {'region': 'Norte', 'total': 15234.56, 'count': 25},
    {'region': 'Sur', 'total': 18765.43, 'count': 28},
    {'region': 'Este', 'total': 12543.21, 'count': 22},
    {'region': 'Oeste', 'total': 16234.78, 'count': 25}
]
```

**Mejoras observadas:**

- Reducci√≥n de tiempo de ejecuci√≥n versus procesamiento secuencial
- Tasks ejecutadas simult√°neamente sin bloqueo mutuo
- Mantiene trazabilidad de cada proceso regional independiente

## Conexi√≥n con DataOps

### 1. Observabilidad

Prefect implementa observabilidad a trav√©s de:

- **Logging estructurado autom√°tico**: cada task registra ejecuci√≥n, estado y mensajes
- **UI en tiempo real**: visualizaci√≥n de DAGs, estados y dependencias sin configuraci√≥n
- **Tracking de estados granulares**: permite entender exactamente qu√© pas√≥ en cada paso
- **Result persistence**: almacena outputs intermedios para inspecci√≥n post-ejecuci√≥n
- **M√©tricas y alertas**: eventos autom√°ticos para notificaciones

Impacto: Detecci√≥n r√°pida de fallos, debugging con contexto completo, comprensi√≥n del comportamiento sin instrumentaci√≥n manual.

### 2. Reproducibilidad

El caching mejora reproducibilidad mediante:

- **Determinismo garantizado**: mismos inputs ‚Üí mismo resultado siempre
- **Reducci√≥n de variabilidad externa**: cache preserva estado para comparaciones
- **Facilita experimentaci√≥n**: iterar en pasos posteriores sin re-ejecutar anteriores
- **Versionado impl√≠cito**: cambios en inputs generan nueva cache, creando historial
- **Debugging consistente**: reproducir ejecuciones problem√°ticas con datos cacheados

### 3. CI/CD para Datos

Deployments habilitan CI/CD mediante:

- **Separaci√≥n c√≥digo/ejecuci√≥n**: c√≥digo en Git, deployment define c√≥mo/cu√°ndo ejecutar
- **Promoci√≥n entre ambientes**: mismo c√≥digo, diferentes deployments para dev/staging/prod
- **Versionado autom√°tico**: cada cambio crea nueva versi√≥n, permite rollbacks
- **Integraci√≥n con CI**: crear/actualizar deployments desde GitHub Actions, GitLab CI
- **Testing automatizado**: deployments de prueba en cada PR antes de producci√≥n
- **Infrastructure as Code**: configuraci√≥n versionada y revisada como c√≥digo

## Comparaci√≥n con Alternativas

### Prefect vs Apache Airflow

**Diferencia 1 - Filosof√≠a de desarrollo:**

- **Prefect**: Python nativo sin DSLs, workflows son funciones est√°ndar, inferencia autom√°tica de dependencias
- **Airflow**: Requiere definir DAGs expl√≠citamente con API espec√≠fica, dependencias declaradas con `>>` o `set_upstream()`

**Diferencia 2 - Ejecuci√≥n din√°mica:**

- **Prefect**: Tasks din√°micas en runtime basadas en datos, control de flujo nativo de Python
- **Airflow**: DAG est√°tico definido antes de ejecuci√≥n, limitado para l√≥gica condicional compleja

### Prefect vs Dagster

**Paradigma:**

- **Dagster**: Enfocado en "data assets" (tablas, modelos ML), grafo de dependencias de assets
- **Prefect**: Enfocado en ejecuci√≥n de workflows de tasks

**Target audience:**

- **Dagster**: Analytics Engineering, usuarios de dbt, gesti√≥n de linaje de datos
- **Prefect**: Ingenieros de datos y MLOps generales, flexibilidad de workflows

**Testing:**

- **Dagster**: Framework de testing m√°s robusto para validar transformaciones
- **Prefect**: Testing est√°ndar de Python, enfoque en robustez de ejecuci√≥n

Ambos son modernos, Pythonic, y superiores a Airflow en usabilidad.

## Evidencias

- Ingresar al an√°lisis completo: [Open Practicos](../Practicos/PRactico_15.ipynb)
- Dataset generado: `output.csv` con registros procesados
- Logs de ejecuci√≥n mostrando estados de tasks
- Implementaciones de extensiones: retries, caching, concurrencia

## Reflexi√≥n

Esta actividad proporcion√≥ una comprensi√≥n profunda de orquestaci√≥n moderna de datos con Prefect, contrastando significativamente con enfoques tradicionales. Los conceptos aprendidos son fundamentales para implementar pipelines de datos robustos, escalables y mantenibles.

**Aprendizajes clave:**

1. **Simplicidad Pythonic**: La capacidad de escribir workflows como funciones Python naturales elimina la curva de aprendizaje de DSLs complejos.

2. **Observabilidad nativa**: El tracking autom√°tico de estados y logging estructurado reduce dr√°sticamente el esfuerzo de instrumentaci√≥n.

3. **Resiliencia incorporada**: Features como retries, caching y result persistence est√°n dise√±ados para pipelines de producci√≥n desde el inicio.

4. **Escalabilidad flexible**: Task Runners permiten escalar desde desarrollo local hasta procesamiento distribuido sin cambiar el c√≥digo del flow.

5. **DevOps para datos**: Deployments y scheduling demuestran c√≥mo aplicar pr√°cticas de software engineering a ingenier√≠a de datos.

La conexi√≥n con principios DataOps qued√≥ clara: observabilidad para monitoreo continuo, reproducibilidad para experimentaci√≥n confiable, y CI/CD para iteraci√≥n r√°pida. Estas capacidades son esenciales para equipos de datos modernos que necesitan velocidad sin sacrificar confiabilidad.

**Aplicabilidad pr√°ctica:**

- Automatizaci√≥n de pipelines ETL diarios para reporting de negocio
- Orquestaci√≥n de entrenamiento y deployment de modelos ML
- Gesti√≥n de flujos de datos complejos con m√∫ltiples dependencias
- Implementaci√≥n de validaciones de calidad de datos automatizadas

Prefect se posiciona como una herramienta fundamental en el stack moderno de ingenier√≠a de datos, especialmente para organizaciones que valoran la velocidad de desarrollo y la facilidad de mantenimiento.
