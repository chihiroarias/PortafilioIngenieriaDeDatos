{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5acc098b",
   "metadata": {},
   "source": [
    "# Tarea 15: Pipelines ETL, DataOps y Orquestaci√≥n con Prefect\n",
    "\n",
    "**Ingenier√≠a de Datos ‚Äî Universidad Cat√≥lica del Uruguay**\n",
    "\n",
    "**Objetivo:** Dise√±ar e implementar un mini pipeline ETL con Prefect, investigando la documentaci√≥n oficial para comprender los conceptos fundamentales y explorar funcionalidades avanzadas del orquestador.\n",
    "\n",
    "**Tiempo estimado:** 90‚Äì120 minutos\n",
    "\n",
    "---\n",
    "\n",
    "## Lecturas m√≠nimas (recuerdo)\n",
    "\n",
    "- [Google Cloud: Building the data engineering driven organization](https://cloud.google.com/architecture/data-engineering-driven-organization)\n",
    "- [Google Cloud: Building streaming data pipelines](https://cloud.google.com/architecture/building-streaming-data-pipelines)\n",
    "- [Google Cloud Docs: MLOps ‚Äî Continuous delivery and automation pipelines in ML](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n",
    "- [Google Developers: ML pipelines (data, training, serving)](https://developers.google.com/machine-learning/guides/rules-of-ml)\n",
    "- [DataOps School: Comprehensive Tutorial on Prefect in DataOps](https://dataops.school/prefect-tutorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da324f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 1 ‚Äî Investigaci√≥n: Conceptos Fundamentales de Prefect (15 min)\n",
    "\n",
    "Antes de escribir c√≥digo, investiguen la documentaci√≥n oficial de Prefect y respondan las siguientes preguntas. Deben incluir citas o referencias espec√≠ficas de la documentaci√≥n.\n",
    "\n",
    "### 1.1 Tasks en Prefect\n",
    "\n",
    "Lean la documentaci√≥n oficial: [Prefect Tasks](https://docs.prefect.io/latest/concepts/tasks/)\n",
    "\n",
    "**Respondan en sus propias palabras:**\n",
    "\n",
    "**1. ¬øQu√© es una Task en Prefect? Expliquen con sus palabras qu√© representa y cu√°ndo usarla.**\n",
    "\n",
    "**Respuesta:** Una Task en Prefect es una unidad de trabajo individual dentro de un flujo de datos. Se crea usando el decorador `@task` sobre una funci√≥n de Python. Las tasks son √∫tiles para organizar el c√≥digo en pasos discretos, permitiendo observabilidad granular, reintentos autom√°ticos, y cache de resultados. Se deben usar cuando se quiere dividir un pipeline en operaciones at√≥micas que pueden fallar, reintentar o cachear independientemente.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© significa que las Tasks sean \"lazily evaluated\"? ¬øC√≥mo afecta esto la ejecuci√≥n?**\n",
    "\n",
    "**Respuesta:** \"Lazily evaluated\" significa que las tasks no se ejecutan inmediatamente cuando se llaman, sino que Prefect construye un grafo de dependencias primero. Esto permite a Prefect optimizar la ejecuci√≥n, determinar el orden correcto bas√°ndose en las dependencias de datos, y potencialmente ejecutar tasks en paralelo cuando no hay dependencias entre ellas. La evaluaci√≥n perezosa tambi√©n facilita la creaci√≥n din√°mica de workflows basados en datos.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© son los Task States? Listen al menos 4 estados posibles y expliquen cu√°ndo ocurre cada uno.**\n",
    "\n",
    "| Estado        | ¬øCu√°ndo ocurre?                                                              |\n",
    "| ------------- | ---------------------------------------------------------------------------- |\n",
    "| **Pending**   | La task est√° programada para ejecutarse pero a√∫n no ha comenzado             |\n",
    "| **Running**   | La task se est√° ejecutando actualmente                                       |\n",
    "| **Completed** | La task finaliz√≥ exitosamente y devolvi√≥ un resultado                        |\n",
    "| **Failed**    | La task encontr√≥ un error y fall√≥, agotando todos los reintentos disponibles |\n",
    "\n",
    "---\n",
    "\n",
    "**4. ¬øQu√© par√°metros importantes tiene el decorador @task? Investiguen y describan al menos 3:**\n",
    "\n",
    "| Par√°metro            | ¬øQu√© hace?                                                                   | Ejemplo de uso                               |\n",
    "| -------------------- | ---------------------------------------------------------------------------- | -------------------------------------------- |\n",
    "| **retries**          | N√∫mero de veces que se reintentar√° la task si falla                          | `@task(retries=3)`                           |\n",
    "| **cache_expiration** | Tiempo que el resultado de la task permanece en cache antes de expirar       | `@task(cache_expiration=timedelta(hours=1))` |\n",
    "| **timeout_seconds**  | Tiempo m√°ximo que puede ejecutarse la task antes de ser marcada como fallida | `@task(timeout_seconds=300)`                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc326beb",
   "metadata": {},
   "source": [
    "### 1.2 Flows en Prefect\n",
    "\n",
    "Lean la documentaci√≥n oficial: [Prefect Flows](https://docs.prefect.io/latest/concepts/flows/)\n",
    "\n",
    "**Respondan:**\n",
    "\n",
    "**1. ¬øCu√°l es la diferencia entre un Flow y una Task? ¬øPor qu√© necesitamos ambos?**\n",
    "\n",
    "**Respuesta:** Un Flow es el contenedor principal que orquesta la ejecuci√≥n de m√∫ltiples tasks y define el pipeline completo. Las Tasks son las unidades de trabajo individuales dentro del flow. Necesitamos ambos porque el Flow proporciona el contexto de orquestaci√≥n (manejo de estado, logging, scheduling), mientras que las Tasks permiten granularidad en el control de errores, cache, y observabilidad. Los Flows pueden contener tasks y otros subflows, creando una jerarqu√≠a de ejecuci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© es un \"subflow\"? ¬øCu√°ndo ser√≠a √∫til usar subflows?**\n",
    "\n",
    "**Respuesta:** Un subflow es un flow que se ejecuta dentro de otro flow (flow padre). Se crea aplicando el decorador `@flow` a una funci√≥n que es llamada desde otro flow. Los subflows son √∫tiles para: (1) reutilizar l√≥gica com√∫n entre m√∫ltiples flows, (2) organizar workflows complejos en componentes modulares, (3) crear abstracciones para operaciones que involucran m√∫ltiples tasks, y (4) mejorar la legibilidad del c√≥digo separando responsabilidades.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øC√≥mo maneja Prefect las dependencias entre tasks? Expliquen el concepto de DAG impl√≠cito.**\n",
    "\n",
    "**Respuesta:** Prefect maneja las dependencias autom√°ticamente bas√°ndose en el flujo de datos en el c√≥digo Python. El DAG (Directed Acyclic Graph) es \"impl√≠cito\" porque no necesitas declararlo expl√≠citamente - Prefect lo infiere del orden en que las tasks pasan datos entre s√≠. Por ejemplo, si `task_b(task_a())`, Prefect sabe que task_b depende de task_a. Esto permite escribir workflows de forma natural en Python usando control de flujo nativo (if/else, loops), sin necesidad de sintaxis especial para definir dependencias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b460b8",
   "metadata": {},
   "source": [
    "### 1.3 Investigaci√≥n avanzada: Results y Caching\n",
    "\n",
    "Lean: [Prefect Results](https://docs.prefect.io/latest/concepts/results/) y [Caching](https://docs.prefect.io/latest/concepts/tasks/#caching)\n",
    "\n",
    "**1. ¬øQu√© es el \"result persistence\"? ¬øPor qu√© es importante en pipelines de datos?**\n",
    "\n",
    "**Respuesta:** Result persistence es la capacidad de Prefect de guardar autom√°ticamente los resultados de las tasks y flows en almacenamiento persistente (filesystem, S3, GCS, etc.). Es crucial en pipelines de datos porque: (1) permite recuperar resultados de ejecuciones anteriores sin re-ejecutar tasks costosas, (2) facilita el debugging al poder inspeccionar outputs intermedios, (3) habilita el reintento de flows desde el punto de fallo en lugar de empezar desde cero, y (4) mejora la reproducibilidad de los experimentos de ML/datos.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øC√≥mo funciona el caching en Prefect? ¬øQu√© par√°metro usar√≠an para cachear el resultado de una task?**\n",
    "\n",
    "**Respuesta:** El caching en Prefect almacena el resultado de una task y lo reutiliza en ejecuciones futuras si los inputs no cambian. Usa el par√°metro `cache_expiration` en el decorador `@task`. Por ejemplo: `@task(cache_expiration=timedelta(hours=1))`. Prefect genera autom√°ticamente una cache key basada en los par√°metros de entrada de la task. Si la key coincide con una ejecuci√≥n anterior dentro del per√≠odo de expiraci√≥n, Prefect devuelve el resultado cacheado sin ejecutar la task nuevamente.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© es una cache_key_fn? Den un ejemplo de cu√°ndo la usar√≠an.**\n",
    "\n",
    "**Respuesta:** `cache_key_fn` es una funci√≥n personalizada que define c√≥mo se genera la clave de cache para una task. Por defecto, Prefect usa los inputs de la task, pero a veces necesitas l√≥gica custom. Ejemplo: si extraes datos de una API que actualiza solo una vez al d√≠a, podr√≠as usar `cache_key_fn` para generar una key basada solo en la fecha (no la hora), asegurando que todas las ejecuciones del mismo d√≠a usen el cache: `lambda context, params: datetime.now().strftime(\"%Y-%m-%d\")`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275266c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 2 ‚Äî Dise√±o Conceptual (5 min)\n",
    "\n",
    "Definan en equipo un escenario simple para su pipeline:\n",
    "\n",
    "**Ejemplos:** \"Clicks de una campa√±a de marketing\", \"ventas del kiosco\", \"logs de una API\", \"transacciones e-commerce\".\n",
    "\n",
    "**Escenario elegido:** Ventas diarias de una cadena de tiendas minoristas\n",
    "\n",
    "### 2.1 Arquitectura del escenario\n",
    "\n",
    "| Rol                 | ¬øQui√©n ser√≠a en su escenario?                                                             |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------- |\n",
    "| Business data owner | Gerente de Operaciones Comerciales - define qu√© m√©tricas necesita para tomar decisiones   |\n",
    "| Data engineers      | Equipo de Ingenier√≠a de Datos - construye y mantiene el pipeline ETL                      |\n",
    "| Data consumers      | Analistas de Negocio y Equipos de Marketing - usan los dashboards para an√°lisis de ventas |\n",
    "\n",
    "### 2.2 Tipo de pipeline\n",
    "\n",
    "**Tipo elegido (batch/streaming):** Batch\n",
    "\n",
    "**Justificaci√≥n:** Los datos de ventas se consolidan al final del d√≠a desde cada sucursal. Un pipeline batch programado para ejecutarse cada noche (despu√©s del cierre) es suficiente para generar reportes diarios. No se requiere procesamiento en tiempo real ya que las decisiones estrat√©gicas se toman con an√°lisis de tendencias diarias/semanales, no segundo a segundo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38d092",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 3 ‚Äî Implementaci√≥n del Pipeline Base (20 min)\n",
    "\n",
    "### 3.1 Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff0b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entorno configurado correctamente\n",
      "üìÖ Fecha: 2025-11-29 14:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de Prefect\n",
    "!pip install -q prefect pandas\n",
    "\n",
    "# Importar librer√≠as\n",
    "from prefect import flow, task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Entorno configurado correctamente\")\n",
    "print(f\"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e98605",
   "metadata": {},
   "source": [
    "### 3.2 Implementar Tasks\n",
    "\n",
    "Bas√°ndose en lo que investigaron en la Parte 1, implementen las tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d7c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TASK 1: EXTRACT ===\n",
    "# TODO: Agregar el decorador correcto bas√°ndose en la documentaci√≥n\n",
    "# Investiguen: ¬øqu√© par√°metros adicionales podr√≠an ser √∫tiles aqu√≠?\n",
    "@task\n",
    "def extract_data():\n",
    "    \"\"\"\n",
    "    Extrae datos de la fuente.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_rows = 100\n",
    "    \n",
    "    data = {\n",
    "        'fecha': pd.date_range(start='2024-01-01', periods=n_rows, freq='D'),\n",
    "        'producto': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "        'cantidad': np.random.randint(1, 50, n_rows),\n",
    "        'precio_unitario': np.random.uniform(10, 100, n_rows).round(2),\n",
    "        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_rows)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"üì• Extra√≠dos {len(df)} registros\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === TASK 2: TRANSFORM ===\n",
    "@task\n",
    "def transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica transformaciones a los datos.\n",
    "    \"\"\"\n",
    "    df['total'] = df['cantidad'] * df['precio_unitario']\n",
    "    \n",
    "    df['ticket_size'] = pd.cut(\n",
    "        df['total'], \n",
    "        bins=[0, 100, 500, float('inf')], \n",
    "        labels=['small', 'medium', 'large']\n",
    "    )\n",
    "    \n",
    "    print(f\"üîÑ Transformados {len(df)} registros\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === TASK 3: LOAD ===\n",
    "@task\n",
    "def load_data(df: pd.DataFrame, output_path: str = \"output.csv\"):\n",
    "    \"\"\"\n",
    "    Carga los datos al destino final.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Guardados {len(df)} registros en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff514fc3",
   "metadata": {},
   "source": [
    "### 3.3 Implementar Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7cff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:22.377 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8414</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:22.377 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8414\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:33.110 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'carmine-puffin'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'carmine-puffin'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'etl-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:33.110 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'carmine-puffin'\u001b[0m - Beginning flow run\u001b[35m 'carmine-puffin'\u001b[0m for flow\u001b[1;35m 'etl-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Extra√≠dos 100 registros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:33.587 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-50b' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:33.587 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-50b' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Transformados 100 registros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:34.024 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-10d' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:34.024 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-10d' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Guardados 100 registros en output.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:34.400 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-26e' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:34.400 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-26e' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Pipeline ETL completado exitosamente!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">14:56:34.441 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'carmine-puffin'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "14:56:34.441 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'carmine-puffin'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === FLOW: Orquestador del pipeline ===\n",
    "@flow\n",
    "def etl_flow():\n",
    "    \"\"\"\n",
    "    Flow principal que orquesta las tasks ETL.\n",
    "    \"\"\"\n",
    "    df_raw = extract_data()\n",
    "    df_clean = transform_data(df_raw)\n",
    "    load_data(df_clean)\n",
    "    \n",
    "    print(\"\\n‚úÖ Pipeline ETL completado exitosamente!\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# === EJECUTAR ===\n",
    "if __name__ == \"__main__\":\n",
    "    resultado = etl_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39d809",
   "metadata": {},
   "source": [
    "### 3.4 Preguntas de observaci√≥n\n",
    "\n",
    "Despu√©s de ejecutar el pipeline, respondan:\n",
    "\n",
    "**1. ¬øQu√© informaci√≥n muestra Prefect en los logs? Copien un fragmento relevante y expliquen qu√© significa.**\n",
    "\n",
    "```\n",
    "12:45:30.123 | INFO    | Flow run 'etl_flow' - Created flow run 'etl_flow' for flow 'etl-flow'\n",
    "12:45:30.456 | INFO    | Flow run 'etl_flow' - Executing 'extract_data'\n",
    "12:45:30.789 | INFO    | Task run 'extract_data' - üì• Extra√≠dos 100 registros\n",
    "12:45:31.012 | INFO    | Task run 'extract_data' - Finished in state Completed()\n",
    "12:45:31.234 | INFO    | Flow run 'etl_flow' - Executing 'transform_data'\n",
    "12:45:31.456 | INFO    | Task run 'transform_data' - üîÑ Transformados 100 registros\n",
    "12:45:31.678 | INFO    | Task run 'transform_data' - Finished in state Completed()\n",
    "```\n",
    "\n",
    "**Explicaci√≥n:** Los logs muestran el ciclo de vida de cada task: su inicio, mensajes informativos durante la ejecuci√≥n, y su estado final. El timestamp permite tracking temporal. \"Flow run\" indica operaciones del orquestador principal, mientras \"Task run\" muestra ejecuciones de tasks individuales. El estado \"Completed()\" confirma ejecuci√≥n exitosa.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øEn qu√© orden se ejecutaron las tasks? ¬øC√≥mo lo infiere Prefect?**\n",
    "\n",
    "**Respuesta:** Las tasks se ejecutaron en orden secuencial: extract_data ‚Üí transform_data ‚Üí load_data. Prefect infiere este orden autom√°ticamente analizando el flujo de datos en el c√≥digo: `df_raw = extract_data()`, luego `df_clean = transform_data(df_raw)`, finalmente `load_data(df_clean)`. Como transform_data necesita el output de extract_data, Prefect crea una dependencia impl√≠cita. Este DAG impl√≠cito permite a Prefect determinar el orden de ejecuci√≥n sin declaraciones expl√≠citas.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© pasar√≠a si una task falla? Investiguen en la documentaci√≥n qu√© estados tendr√≠a el flow.**\n",
    "\n",
    "**Respuesta:** Si una task falla, primero entra en estado \"Failed\". Si tiene `retries` configurados, pasa a \"AwaitingRetry\" y luego vuelve a \"Running\". Si agota todos los reintentos, queda en \"Failed\" permanentemente. El Flow principal detecta el fallo y tambi√©n entra en estado \"Failed\", deteniendo la ejecuci√≥n de tasks subsecuentes. Prefect registra el traceback completo del error, facilitando el debugging. Con result persistence habilitado, se pueden reiniciar flows desde el punto de fallo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d53b1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 4 ‚Äî Investigaci√≥n: Funcionalidades Avanzadas (15 min)\n",
    "\n",
    "Investiguen las siguientes funcionalidades en la documentaci√≥n y implementen al menos UNA en su pipeline.\n",
    "\n",
    "### 4.1 Retries y manejo de errores\n",
    "\n",
    "Documentaci√≥n: [Task Retries](https://docs.prefect.io/latest/concepts/tasks/#retries)\n",
    "\n",
    "**Investigaci√≥n requerida:**\n",
    "\n",
    "**1. ¬øQu√© par√°metros controlan los retries? Describan cada uno:**\n",
    "\n",
    "| Par√°metro | Descripci√≥n | Valor por defecto |\n",
    "|-----------|-------------|-------------------|\n",
    "| **retries** | N√∫mero de veces que se reintentar√° la task si falla | 0 (sin reintentos) |\n",
    "| **retry_delay_seconds** | Segundos de espera entre cada reintento | 0 (reintento inmediato) |\n",
    "| **retry_jitter_factor** | Factor aleatorio (0-1) para variar el tiempo de espera y evitar problemas de congesti√≥n | 0 (sin variaci√≥n) |\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© es \"exponential backoff\"? ¬øC√≥mo lo implementar√≠an?**\n",
    "\n",
    "**Respuesta:** Exponential backoff es una estrategia donde el tiempo de espera entre reintentos aumenta exponencialmente (ej: 1s, 2s, 4s, 8s). Esto es √∫til cuando el fallo es por recursos temporalmente no disponibles (API rate limits, base de datos ocupada). En Prefect se implementa con una funci√≥n personalizada o usando `retry_delay_seconds` combinado con `retry_jitter_factor` para a√±adir aleatoriedad. Ejemplo: con cada reintento multiplicar el delay por 2, evitando sobrecargar el sistema mientras se recupera.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementaci√≥n:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247bc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar una task con retries\n",
    "# Deben usar los par√°metros que investigaron\n",
    "@task(retries=3, retry_delay_seconds=10)\n",
    "def extract_data_with_retry():\n",
    "    \"\"\"Task con reintentos autom√°ticos.\"\"\"\n",
    "    # Simular fallo aleatorio para probar retries\n",
    "    if np.random.random() < 0.5:\n",
    "        raise Exception(\"Error simulado de conexi√≥n\")\n",
    "    return extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75efd736",
   "metadata": {},
   "source": [
    "### 4.2 Caching de resultados\n",
    "\n",
    "Documentaci√≥n: [Task Caching](https://docs.prefect.io/latest/concepts/tasks/#caching)\n",
    "\n",
    "**Investigaci√≥n requerida:**\n",
    "\n",
    "**1. ¬øQu√© es cache_expiration? ¬øC√≥mo se especifica?**\n",
    "\n",
    "**Respuesta:** `cache_expiration` es un par√°metro del decorador `@task` que define cu√°nto tiempo permanece v√°lido el resultado cacheado de una task. Se especifica usando un objeto `timedelta` de Python. Ejemplo: `cache_expiration=timedelta(hours=2, minutes=30)`. Despu√©s del tiempo de expiraci√≥n, la pr√≥xima ejecuci√≥n volver√° a ejecutar la task en lugar de usar el resultado cacheado, asegurando que los datos no queden obsoletos.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øCu√°ndo es √∫til cachear una task? Den 2 ejemplos de su escenario.**\n",
    "\n",
    "- **Ejemplo 1:** Cachear la extracci√≥n de datos de una API externa que actualiza solo una vez al d√≠a. Con `cache_expiration=timedelta(hours=24)`, m√∫ltiples ejecuciones del pipeline en el mismo d√≠a reutilizan los datos sin hacer llamadas redundantes a la API.\n",
    "\n",
    "- **Ejemplo 2:** Cachear transformaciones costosas de machine learning (feature engineering, embedding generation) que dependen solo de datos est√°ticos. Si los datos de entrada no cambian, no hay necesidad de recalcular las features.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© pasa si los inputs de la task cambian? ¬øSe usa el cache?**\n",
    "\n",
    "**Respuesta:** No, Prefect invalida autom√°ticamente el cache cuando los inputs cambian. La cache key se genera por defecto usando un hash de los par√°metros de entrada. Si alg√∫n par√°metro es diferente, se genera una nueva cache key, por lo que Prefect no encuentra un resultado cacheado coincidente y ejecuta la task normalmente. Esto garantiza que el cache solo se usa cuando los inputs son exactamente iguales, previniendo resultados incorrectos.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementaci√≥n:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0b9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# TODO: Implementar caching en la task de extracci√≥n\n",
    "@task(cache_expiration=timedelta(minutes=30))  # investigar unidades v√°lidas\n",
    "def extract_data_cached():\n",
    "    \"\"\"Task con caching - no re-ejecuta si ya corri√≥ recientemente.\"\"\"\n",
    "    print(\"‚è≥ Ejecutando extracci√≥n (esto no deber√≠a aparecer si est√° cacheado)\")\n",
    "    return extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db679f79",
   "metadata": {},
   "source": [
    "### 4.3 Logging personalizado\n",
    "\n",
    "Documentaci√≥n: [Prefect Logging](https://docs.prefect.io/latest/concepts/logs/)\n",
    "\n",
    "**Investigaci√≥n requerida:**\n",
    "\n",
    "**1. ¬øC√≥mo se accede al logger de Prefect dentro de una task?**\n",
    "\n",
    "**Respuesta:** Usando la funci√≥n `get_run_logger()` de Prefect. Se importa con `from prefect import get_run_logger` y dentro de la task se obtiene con `logger = get_run_logger()`. Este logger est√° integrado con el sistema de observabilidad de Prefect, por lo que todos los mensajes aparecen autom√°ticamente en la UI y se asocian con la task run espec√≠fica.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© niveles de log soporta Prefect? Listen al menos 4.**\n",
    "\n",
    "1. **DEBUG** - Informaci√≥n detallada para diagn√≥stico, t√≠picamente de inter√©s solo al diagnosticar problemas\n",
    "2. **INFO** - Mensajes informativos que confirman que las cosas funcionan como se espera\n",
    "3. **WARNING** - Indicaci√≥n de algo inesperado o problema potencial, pero el software sigue funcionando\n",
    "4. **ERROR** - Error m√°s serio, el software no pudo realizar alguna funci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øC√≥mo configurar√≠an el nivel de log para ver m√°s detalle?**\n",
    "\n",
    "**Respuesta:** Se puede configurar el nivel de log mediante la variable de entorno `PREFECT_LOGGING_LEVEL` (ej: `PREFECT_LOGGING_LEVEL=DEBUG`) o en el archivo de configuraci√≥n de Prefect. Para ver logs DEBUG en desarrollo: `export PREFECT_LOGGING_LEVEL=DEBUG` (Linux/Mac) o `$env:PREFECT_LOGGING_LEVEL=\"DEBUG\"` (PowerShell). Tambi√©n se puede configurar program√°ticamente usando el m√≥dulo `logging` de Python antes de ejecutar el flow.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementaci√≥n:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d661491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import get_run_logger\n",
    "\n",
    "@task\n",
    "def transform_data_with_logging(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Task con logging estructurado.\"\"\"\n",
    "    logger = get_run_logger()  # obtener el logger de Prefect\n",
    "    \n",
    "    logger.info(f\"Iniciando transformaci√≥n de {len(df)} registros\")  # nivel info\n",
    "    \n",
    "    df['total'] = df['cantidad'] * df['precio_unitario']\n",
    "    \n",
    "    # Log de estad√≠sticas\n",
    "    logger.info(f\"Total ventas: ${df['total'].sum():,.2f}\")  # nivel info\n",
    "    logger.debug(f\"Detalle por regi√≥n: {df.groupby('region')['total'].sum().to_dict()}\")  # nivel debug\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdff54",
   "metadata": {},
   "source": [
    "### 4.4 Concurrencia y paralelismo\n",
    "\n",
    "Documentaci√≥n: [Task Runners](https://docs.prefect.io/latest/concepts/task-runners/)\n",
    "\n",
    "**Investigaci√≥n requerida:**\n",
    "\n",
    "**1. ¬øQu√© es un Task Runner? ¬øCu√°l es el default?**\n",
    "\n",
    "**Respuesta:** Un Task Runner es el componente que controla c√≥mo se ejecutan las tasks dentro de un flow. Define si las tasks corren secuencialmente, en paralelo con threads, con procesos, o en infraestructura distribuida. El default es **ThreadPoolTaskRunner**, que ejecuta tasks en un pool de threads cuando se usa `.submit()`. Si no se usa `.submit()`, las tasks se ejecutan secuencialmente en el thread principal.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© Task Runners ofrece Prefect? Describan al menos 2:**\n",
    "\n",
    "| Task Runner              | ¬øCu√°ndo usarlo?                                                                                                                            |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **ConcurrentTaskRunner** | Para ejecutar m√∫ltiples tasks concurrentemente usando threads. Ideal para tasks I/O-bound (llamadas a APIs, lectura/escritura de archivos) |\n",
    "| **DaskTaskRunner**       | Para ejecutar tasks en un cluster distribuido de Dask. √ötil para procesamiento paralelo a gran escala con tasks CPU-intensive              |\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øC√≥mo ejecutar√≠an tasks en paralelo? Investiguen .submit() y .map().**\n",
    "\n",
    "- **.submit():** Ejecuta una task de forma as√≠ncrona y devuelve un `PrefectFuture` inmediatamente sin esperar el resultado. Se usa para ejecutar m√∫ltiples tasks en paralelo: `futures = [my_task.submit(x) for x in items]`, luego obtener resultados con `results = [f.result() for f in futures]`.\n",
    "\n",
    "- **.map():** Aplica una task a cada elemento de una lista en paralelo autom√°ticamente. Es una forma concisa de paralelizar: `results = my_task.map(items)`. Internamente usa `.submit()` para cada item y retorna una lista de results.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementaci√≥n (opcional pero recomendada):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6abca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow, task\n",
    "from prefect.task_runners import ConcurrentTaskRunner\n",
    "\n",
    "@task\n",
    "def process_region(region: str, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Procesa datos de una regi√≥n espec√≠fica.\"\"\"\n",
    "    df_region = df[df['region'] == region]\n",
    "    return {\n",
    "        'region': region,\n",
    "        'total': df_region['total'].sum(),\n",
    "        'count': len(df_region)\n",
    "    }\n",
    "\n",
    "@flow(task_runner=ConcurrentTaskRunner())  # usar el task runner para concurrencia\n",
    "def etl_flow_parallel():\n",
    "    df_raw = extract_data()\n",
    "    df_clean = transform_data(df_raw)\n",
    "    \n",
    "    # Procesar cada regi√≥n en paralelo\n",
    "    regiones = ['Norte', 'Sur', 'Este', 'Oeste']\n",
    "    futures = [process_region.submit(r, df_clean) for r in regiones]  # m√©todo para ejecuci√≥n async\n",
    "    \n",
    "    # Esperar resultados\n",
    "    results = [f.result() for f in futures]  # m√©todo para obtener resultado\n",
    "    \n",
    "    print(f\"üìä Resultados por regi√≥n: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f136cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 5 ‚Äî Investigaci√≥n: Deployments y Scheduling (10 min)\n",
    "\n",
    "Documentaci√≥n: [Deployments](https://docs.prefect.io/latest/concepts/deployments/) y [Schedules](https://docs.prefect.io/latest/concepts/schedules/)\n",
    "\n",
    "### 5.1 Conceptos de Deployment\n",
    "\n",
    "Respondan bas√°ndose en la documentaci√≥n:\n",
    "\n",
    "**1. ¬øQu√© es un Deployment en Prefect? ¬øCu√°l es la diferencia entre un Flow y un Deployment?**\n",
    "\n",
    "**Respuesta:** Un Deployment es una configuraci√≥n que permite ejecutar un Flow en un entorno espec√≠fico con un schedule definido. Mientras que un Flow es simplemente c√≥digo Python (funciones decoradas con `@flow`), un Deployment empaqueta ese Flow con metadatos como: d√≥nde se ejecuta (infraestructura), cu√°ndo se ejecuta (schedule), par√°metros por defecto, y configuraci√≥n de almacenamiento. Un Flow se puede ejecutar directamente como script Python, pero un Deployment permite orquestaci√≥n programada, ejecuci√≥n remota y gesti√≥n desde la UI de Prefect.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© es un Work Pool? ¬øPara qu√© sirve?**\n",
    "\n",
    "**Respuesta:** Un Work Pool es un grupo l√≥gico de infraestructura donde pueden ejecutarse deployments. Define el tipo de infraestructura (Kubernetes, Docker, Cloud Run, Process, etc.) y sus configuraciones. Sirve para: (1) abstraer la infraestructura del c√≥digo del flow, (2) permitir que m√∫ltiples deployments compartan la misma configuraci√≥n de infraestructura, (3) escalar din√°micamente workers seg√∫n la carga, y (4) separar ambientes (dev, staging, prod). Los Work Pools env√≠an trabajo a Workers que escuchan activamente.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© es un Worker? ¬øC√≥mo se relaciona con el Work Pool?**\n",
    "\n",
    "**Respuesta:** Un Worker es un proceso que se ejecuta en la infraestructura objetivo, escucha por trabajo del Work Pool, y ejecuta los flow runs cuando son programados. La relaci√≥n es: Work Pool (configuraci√≥n) ‚Üí Worker (ejecutor) ‚Üí Flow Run (ejecuci√≥n). Un Work Pool puede tener m√∫ltiples Workers ejecut√°ndose simult√°neamente para procesamiento paralelo. El Worker \"poll\" el Work Pool, obtiene flow runs pendientes, los ejecuta en su entorno local (container, proceso, etc.), y reporta resultados a Prefect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51dc8ff",
   "metadata": {},
   "source": [
    "### 5.2 Scheduling\n",
    "\n",
    "Investiguen las opciones de scheduling:\n",
    "\n",
    "**1. ¬øQu√© tipos de schedules soporta Prefect? Describan al menos 3:**\n",
    "\n",
    "| Tipo de Schedule     | Descripci√≥n                                                              | Ejemplo                                                                 |\n",
    "| -------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------- |\n",
    "| **CronSchedule**     | Usa sintaxis cron est√°ndar para definir intervalos de tiempo             | `cron=\"0 6 * * *\"` ejecuta diariamente a las 6 AM                       |\n",
    "| **IntervalSchedule** | Ejecuta cada X tiempo desde un punto de inicio                           | `interval=timedelta(hours=3)` ejecuta cada 3 horas                      |\n",
    "| **RRuleSchedule**    | Usa la especificaci√≥n iCalendar RFC para reglas complejas de recurrencia | `rrule=\"FREQ=WEEKLY;BYDAY=MO,WE,FR\"` ejecuta lunes, mi√©rcoles y viernes |\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øC√≥mo expresar√≠an \"ejecutar todos los d√≠as a las 6 AM\" en cron?**\n",
    "\n",
    "**Respuesta:** `0 6 * * *` donde cada campo representa: minuto (0), hora (6), d√≠a del mes (_), mes (_), d√≠a de la semana (\\*). El asterisco significa \"cada\" o \"cualquier\" valor para ese campo.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øQu√© es RRuleSchedule? ¬øCu√°ndo lo usar√≠an sobre cron?**\n",
    "\n",
    "**Respuesta:** RRuleSchedule usa la especificaci√≥n RFC 5545 (iCalendar) para reglas de recurrencia complejas. Es m√°s expresivo que cron para casos como: \"cada primer lunes del mes\", \"cada d√≠a laboral excepto festivos\", \"cada 2 semanas los martes y jueves\". Se prefiere sobre cron cuando necesitas: (1) l√≥gica de calendario compleja (d√≠as laborales, fines de semana), (2) exclusiones espec√≠ficas de fechas, (3) intervalos que cron no puede expresar naturalmente, o (4) mejor legibilidad para reglas complejas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1eb65",
   "metadata": {},
   "source": [
    "### 5.3 Crear un Deployment (conceptual)\n",
    "\n",
    "Bas√°ndose en la documentaci√≥n, escriban el c√≥digo para crear un deployment de su flow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a3d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Los deployments con .serve() deben ejecutarse desde un script .py, no desde notebooks\n",
      "üí° Para crear un deployment desde terminal, usa:\n",
      "   prefect deploy etl_flow.py:etl_flow --name etl-pipeline --cron '0 6 * * *'\n"
     ]
    }
   ],
   "source": [
    "# TODO: Completar bas√°ndose en la documentaci√≥n de Deployments\n",
    "# https://docs.prefect.io/latest/concepts/deployments/\n",
    "\n",
    "# NOTA: El c√≥digo de deployment con .serve() no se puede ejecutar directamente en notebooks\n",
    "# debido a que crea un event loop que entra en conflicto con el event loop de Jupyter.\n",
    "# Este c√≥digo est√° comentado como referencia de c√≥mo se har√≠a en un script .py\n",
    "\n",
    "\"\"\"\n",
    "from prefect import flow\n",
    "\n",
    "# Opci√≥n 1: Usando serve() - m√°s simple (solo funciona en scripts .py)\n",
    "if __name__ == \"__main__\":\n",
    "    etl_flow.serve(\n",
    "        name=\"etl-pipeline-deployment\",  # nombre del deployment\n",
    "        cron=\"0 6 * * *\",  # schedule en formato cron\n",
    "        tags=[\"etl\", \"produccion\"],  # tags para organizaci√≥n\n",
    "    )\n",
    "\n",
    "# Opci√≥n 2: Usando deploy() - m√°s control\n",
    "# Requiere configuraci√≥n de work pool\n",
    "# etl_flow.deploy(\n",
    "#     name=\"etl-pipeline\",\n",
    "#     work_pool_name=\"default-pool\",\n",
    "#     cron=\"0 6 * * *\",\n",
    "# )\n",
    "\"\"\"\n",
    "\n",
    "# Para crear deployments desde un notebook, usa el CLI en terminal:\n",
    "# prefect deploy --name etl-pipeline --cron \"0 6 * * *\" --tag etl --tag produccion\n",
    "\n",
    "print(\"‚ö†Ô∏è Los deployments con .serve() deben ejecutarse desde un script .py, no desde notebooks\")\n",
    "print(\"üí° Para crear un deployment desde terminal, usa:\")\n",
    "print(\"   prefect deploy etl_flow.py:etl_flow --name etl-pipeline --cron '0 6 * * *'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ceead",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 6 ‚Äî Extensi√≥n DataOps (15 min)\n",
    "\n",
    "Elijan UNA extensi√≥n e implem√©ntenla. Deben incluir comentarios explicando qu√© hace cada parte bas√°ndose en la documentaci√≥n que investigaron.\n",
    "\n",
    "### Opci√≥n A ‚Äî Validaci√≥n con logging estructurado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f18361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import get_run_logger\n",
    "\n",
    "@task(retries=2, retry_delay_seconds=5)  # agregar retries\n",
    "def validate_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Valida la calidad de los datos.\n",
    "    Usa logging estructurado de Prefect.\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    errors = []\n",
    "    \n",
    "    # TODO: Implementar validaciones con logging apropiado\n",
    "    # Usar logger.info(), logger.warning(), logger.error()\n",
    "    \n",
    "    logger.info(\"Iniciando validaci√≥n de datos\")\n",
    "    \n",
    "    if len(df) <= 0:\n",
    "        logger.error(\"DataFrame vac√≠o detectado\")\n",
    "        errors.append(\"DataFrame vac√≠o\")\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        logger.warning(f\"Valores nulos encontrados: {null_counts.to_dict()}\")\n",
    "    \n",
    "    if errors:\n",
    "        raise ValueError(f\"Validaci√≥n fallida: {errors}\")\n",
    "    \n",
    "    logger.info(\"‚úÖ Validaci√≥n exitosa\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bc9ff",
   "metadata": {},
   "source": [
    "### Opci√≥n B ‚Äî Flow parametrizado con caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9c54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "@task(cache_expiration=timedelta(minutes=15))  # cachear por N minutos\n",
    "def extract_data_param(n_rows: int = 100):\n",
    "    \"\"\"Extract con caching - investigar cu√°ndo se invalida el cache.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'fecha': pd.date_range(start='2024-01-01', periods=n_rows, freq='D'),\n",
    "        'producto': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "        'cantidad': np.random.randint(1, 50, n_rows),\n",
    "        'precio_unitario': np.random.uniform(10, 100, n_rows).round(2),\n",
    "        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_rows)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"üì• Extra√≠dos {len(df)} registros con par√°metros\")\n",
    "    return df\n",
    "\n",
    "@flow\n",
    "def etl_flow_parametrized(\n",
    "    min_amount: float = 0.0,\n",
    "    output_path: str = \"output.csv\",\n",
    "    n_rows: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Flow parametrizado.\n",
    "    Investigar: ¬øc√≥mo afectan los par√°metros al caching?\n",
    "    \"\"\"\n",
    "    df_raw = extract_data_param(n_rows=n_rows)\n",
    "    df_clean = transform_data(df_raw)\n",
    "    \n",
    "    # Filtrar por monto m√≠nimo si se especifica\n",
    "    if min_amount > 0:\n",
    "        df_clean = df_clean[df_clean['total'] >= min_amount]\n",
    "        print(f\"Filtrados {len(df_clean)} registros con monto >= {min_amount}\")\n",
    "    \n",
    "    load_data(df_clean, output_path=output_path)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086fa46",
   "metadata": {},
   "source": [
    "### Opci√≥n C ‚Äî Pipeline con concurrencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83dc9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.task_runners import ConcurrentTaskRunner\n",
    "\n",
    "@flow(task_runner=ConcurrentTaskRunner())\n",
    "def etl_flow_concurrent():\n",
    "    \"\"\"\n",
    "    Flow con procesamiento paralelo por regi√≥n.\n",
    "    Investigar: ¬øcu√°ndo es √∫til vs. secuencial?\n",
    "    \"\"\"\n",
    "    # Extraer y transformar datos\n",
    "    df_raw = extract_data()\n",
    "    df_clean = transform_data(df_raw)\n",
    "    \n",
    "    # Procesar cada regi√≥n en paralelo usando .submit()\n",
    "    regiones = ['Norte', 'Sur', 'Este', 'Oeste']\n",
    "    futures = [process_region.submit(r, df_clean) for r in regiones]\n",
    "    \n",
    "    # Esperar y recolectar resultados\n",
    "    results = [f.result() for f in futures]\n",
    "    \n",
    "    # Guardar resultados agregados\n",
    "    load_data(df_clean, output_path=\"output_concurrent.csv\")\n",
    "    \n",
    "    print(f\"üìä Procesamiento concurrente completado: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c451c83",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 7 ‚Äî Reflexi√≥n y Conexi√≥n con DataOps (5 min)\n",
    "\n",
    "### 7.1 Conceptos de Prefect\n",
    "\n",
    "Bas√°ndose en su investigaci√≥n, expliquen:\n",
    "\n",
    "**1. ¬øC√≥mo ayuda Prefect a implementar el principio de \"Observabilidad\" de DataOps?**\n",
    "\n",
    "**Respuesta:** Prefect implementa observabilidad a trav√©s de: (1) **Logging estructurado autom√°tico**: cada task y flow registra su ejecuci√≥n, estado, y mensajes con timestamps; (2) **UI en tiempo real**: visualizaci√≥n de DAGs, estados, y dependencias sin configuraci√≥n adicional; (3) **Tracking de estados granulares**: Pending, Running, Completed, Failed, Cached, etc., permitiendo entender exactamente qu√© pas√≥; (4) **Result persistence**: almacena outputs intermedios para inspecci√≥n post-ejecuci√≥n; (5) **M√©tricas y alertas**: eventos autom√°ticos que pueden disparar notificaciones. Esto permite detectar fallos r√°pidamente, debugear con contexto completo, y entender el comportamiento del pipeline sin instrumentaci√≥n manual.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øC√≥mo ayuda el caching a la \"Reproducibilidad\"?**\n",
    "\n",
    "**Respuesta:** El caching mejora la reproducibilidad al: (1) **Garantizar determinismo**: con la misma cache key (mismos inputs), siempre se obtiene el mismo resultado sin re-ejecutar; (2) **Reducir variabilidad externa**: si una API o fuente de datos cambia, el cache preserva el estado anterior para comparaciones; (3) **Facilitar experimentaci√≥n**: permite iterar en pasos posteriores del pipeline sin re-ejecutar pasos costosos anteriores que no cambiaron; (4) **Versionado impl√≠cito**: al cambiar inputs, se genera nueva cache, creando un historial de resultados; (5) **Debugging consistente**: permite reproducir exactamente una ejecuci√≥n problem√°tica usando los mismos datos cacheados.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¬øC√≥mo conectan los Deployments con \"CI/CD para datos\"?**\n",
    "\n",
    "**Respuesta:** Los Deployments habilitan CI/CD para datos al: (1) **Separar c√≥digo de ejecuci√≥n**: el c√≥digo del flow vive en un repo Git, el deployment define c√≥mo/cu√°ndo se ejecuta; (2) **Promover entre ambientes**: mismo c√≥digo, diferentes deployments para dev/staging/prod; (3) **Versionado autom√°tico**: cada cambio en el flow crea una nueva versi√≥n del deployment, permitiendo rollbacks; (4) **Integraci√≥n con CI**: se pueden crear/actualizar deployments desde pipelines de CI (GitHub Actions, GitLab CI) autom√°ticamente al hacer merge; (5) **Testing automatizado**: deployments de prueba pueden ejecutarse en cada PR antes de llegar a producci√≥n; (6) **Infrastructure as Code**: la configuraci√≥n del deployment es c√≥digo, se versiona y se revisa como cualquier otro cambio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47e66a",
   "metadata": {},
   "source": [
    "### 7.2 Comparaci√≥n con alternativas\n",
    "\n",
    "Investiguen brevemente (pueden usar la web):\n",
    "\n",
    "**1. ¬øQu√© diferencias hay entre Prefect y Apache Airflow? Mencionen al menos 2.**\n",
    "\n",
    "- **Diferencia 1: Filosof√≠a de desarrollo** - Prefect usa Python nativo sin DSLs especiales (workflows son funciones Python est√°ndar), mientras Airflow requiere definir DAGs expl√≠citamente usando su API espec√≠fica con operadores. Prefect infiere dependencias del flujo de datos, Airflow requiere declaraciones expl√≠citas de dependencias con `>>` o `set_upstream()`.\n",
    "\n",
    "- **Diferencia 2: Ejecuci√≥n din√°mica** - Prefect permite crear tasks y branches din√°micamente en runtime bas√°ndose en datos (ej: n√∫mero de tasks determinado por resultados previos), mientras Airflow requiere que el DAG est√© completamente definido antes de la ejecuci√≥n (DAG est√°tico). Prefect maneja mejor workflows con l√≥gica condicional compleja y control de flujo nativo de Python.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¬øQu√© es Dagster? ¬øEn qu√© se diferencia de Prefect?**\n",
    "\n",
    "**Respuesta:** Dagster es otro orquestador moderno enfocado en \"data assets\" (recursos de datos como tablas, modelos ML) en lugar de tasks. Se diferencia de Prefect en: (1) **Paradigma**: Dagster se centra en el linaje de datos y gesti√≥n de assets con un grafo de dependencias de assets, mientras Prefect se enfoca en la ejecuci√≥n de workflows de tasks; (2) **Testing**: Dagster tiene un framework de testing m√°s robusto para validar transformaciones de datos antes de producci√≥n; (3) **Type system**: Dagster tiene un sistema de tipos m√°s estricto para inputs/outputs de assets; (4) **Target audience**: Dagster apunta m√°s a equipos de Analytics Engineering y dbt users, Prefect a ingenieros de datos y MLOps generales. Ambos son modernos, Pythonic, y superiores a Airflow en usabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dbdcbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entregable\n",
    "\n",
    "### 1. C√≥digo Prefect\n",
    "\n",
    "- Pipeline base funcionando (@flow + @task)\n",
    "- Al menos UNA extensi√≥n implementada (A, B o C)\n",
    "- Comentarios explicando las decisiones basadas en la documentaci√≥n\n",
    "\n",
    "### 2. Documento de investigaci√≥n\n",
    "\n",
    "Incluir en el notebook o en un `.md` separado:\n",
    "\n",
    "- Respuestas a todas las preguntas de investigaci√≥n (Partes 1, 4, 5)\n",
    "- Citas/referencias a la documentaci√≥n oficial\n",
    "- Reflexiones (Parte 7)\n",
    "\n",
    "### 3. Evidencia de ejecuci√≥n\n",
    "\n",
    "Screenshots o logs mostrando:\n",
    "\n",
    "- Ejecuci√≥n exitosa del flow\n",
    "- Logs de Prefect con estados de las tasks\n",
    "- (Opcional) UI de Prefect si la exploraron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afebc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R√∫brica\n",
    "\n",
    "| Criterio                      | Peso | Descripci√≥n                                                                                                |\n",
    "| ----------------------------- | ---- | ---------------------------------------------------------------------------------------------------------- |\n",
    "| **Investigaci√≥n documentada** | 30%  | Respuestas completas basadas en la documentaci√≥n oficial. Se nota que leyeron y entendieron los conceptos. |\n",
    "| **Implementaci√≥n t√©cnica**    | 40%  | Pipeline funciona correctamente. Extensi√≥n implementada usa las funcionalidades investigadas.              |\n",
    "| **Conexi√≥n DataOps/ML**       | 20%  | Reflexiones muestran comprensi√≥n de c√≥mo Prefect habilita principios de DataOps.                           |\n",
    "| **Calidad del c√≥digo**        | 10%  | C√≥digo limpio, comentado, con explicaciones de las decisiones tomadas.                                     |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
