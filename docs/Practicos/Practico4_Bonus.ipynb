{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## BONUS: Introducci√≥n a Prefect"
      ],
      "metadata": {
        "id": "N6sIiGjpqNRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Setup B√°sico"
      ],
      "metadata": {
        "id": "npOfr51xqgJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === SETUP PREFECT ===\n",
        "\n",
        "# Instalar Prefect (si no est√° instalado)\n",
        "# !pip install prefect\n",
        "\n",
        "import prefect\n",
        "from prefect import task, flow, get_run_logger\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Prefect instalado y configurado\")\n",
        "print(f\"   Versi√≥n: {prefect.__version__}\")"
      ],
      "metadata": {
        "id": "En4SWk45qjp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Convertir funciones a tasks"
      ],
      "metadata": {
        "id": "-Ry_HDENq1xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === TASKS SIMPLES PARA APRENDER PREFECT ===\n",
        "\n",
        "@task(name=\"Cargar Datos\", retries=2, retry_delay_seconds=3)\n",
        "def cargar_datos(url: str, tipo: str) -> pd.DataFrame:\n",
        "    \"\"\"Task simple para cargar cualquier tipo de datos\"\"\"\n",
        "    logger = get_run_logger()\n",
        "    logger.info(f\"Cargando {tipo} desde: {url}\")\n",
        "\n",
        "    # Cargar seg√∫n el tipo\n",
        "    if tipo == \"trips\":\n",
        "        data = pd.read_parquet(url)  # funci√≥n para Parquet\n",
        "    elif tipo == \"zones\":\n",
        "        data = pd.read_csv(url)      # funci√≥n para CSV\n",
        "    else:  # calendar\n",
        "        data = pd.read_json(url)     # funci√≥n para JSON\n",
        "        data['date'] = pd.to_datetime(data['date']).dt.date  # convertir strings a fechas\n",
        "\n",
        "    logger.info(f\"{tipo} cargado: {data.shape[0]} filas\")\n",
        "    return data\n",
        "\n",
        "\n",
        "@task(name=\"Hacer Join Simple\")\n",
        "def hacer_join_simple(trips: pd.DataFrame, zones: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Task para hacer join b√°sico de trips + zones\"\"\"\n",
        "    logger = get_run_logger()\n",
        "    logger.info(\"Haciendo join simple...\")\n",
        "\n",
        "    # Normalizar columnas\n",
        "    trips.columns = trips.columns.str.lower()   # convertir a min√∫sculas\n",
        "    zones.columns = zones.columns.str.lower()   # misma transformaci√≥n\n",
        "\n",
        "    # Join b√°sico\n",
        "    resultado = trips.merge(zones,              # m√©todo para unir DataFrames\n",
        "                            left_on='pulocationid',   # columna de pickup location en trips\n",
        "                            right_on='locationid',    # columna de location en zones\n",
        "                            how='left')               # tipo de join que mantiene todos los trips\n",
        "\n",
        "    logger.info(f\"Join completado: {len(resultado)} registros\")\n",
        "    return resultado\n",
        "\n",
        "\n",
        "@task(name=\"An√°lisis R√°pido\")\n",
        "def analisis_rapido(data: pd.DataFrame) -> dict:\n",
        "    \"\"\"Task para an√°lisis b√°sico\"\"\"\n",
        "    logger = get_run_logger()\n",
        "    logger.info(\"Haciendo an√°lisis b√°sico...\")\n",
        "\n",
        "    # Stats simples\n",
        "    stats = {\n",
        "        'total_registros': len(data),  # m√©todo para contar valores\n",
        "        'boroughs': data['borough'].value_counts().head(3).to_dict(),  # contar valores √∫nicos\n",
        "        'distancia_promedio': round(data['trip_distance'].mean(), 2),  # m√©todo para promedio\n",
        "        'tarifa_promedio': round(data['total_amount'].mean(), 2)       # m√©todo para promedio\n",
        "    }\n",
        "\n",
        "    logger.info(f\"An√°lisis completado: {stats['total_registros']} registros\")\n",
        "    return stats"
      ],
      "metadata": {
        "id": "tr1QXnLjrwVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Crear un flow simple"
      ],
      "metadata": {
        "id": "Spw2OdMqr10M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === FLOW PRINCIPAL (EL PIPELINE COMPLETO) ===\n",
        "\n",
        "@flow(name=\"Pipeline Simple NYC Taxi\")\n",
        "def pipeline_taxi_simple():\n",
        "    \"\"\"Flow simple que conecta todos los tasks\"\"\"\n",
        "\n",
        "    logger = get_run_logger()\n",
        "    logger.info(\"Iniciando pipeline simple...\")\n",
        "\n",
        "    # URLs de datos\n",
        "    trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
        "    zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
        "\n",
        "    # PASO 1: Cargar datos (con retry autom√°tico si falla)\n",
        "    logger.info(\"Paso 1: Cargando datos...\")\n",
        "    trips = cargar_datos(trips_url, \"trips\")    # tipo de datos = trips\n",
        "    zones = cargar_datos(zones_url, \"zones\")    # tipo de datos = zones\n",
        "\n",
        "    # PASO 2: Hacer join\n",
        "    logger.info(\"Paso 2: Haciendo join...\")\n",
        "    data_unida = hacer_join_simple(trips, zones)\n",
        "\n",
        "    # PASO 3: An√°lisis b√°sico\n",
        "    logger.info(\"Paso 3: Analizando...\")\n",
        "    resultados = analisis_rapido(data_unida)\n",
        "\n",
        "    # PASO 4: Mostrar resultados\n",
        "    logger.info(\"Pipeline completado!\")\n",
        "    logger.info(f\"Resultados: {resultados}\")\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "WvcS0aNdr9kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4: Ejecutar el Pipeline"
      ],
      "metadata": {
        "id": "1qkpoyR_sMeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === EJECUTAR EL PIPELINE ===\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Ejecutando pipeline simple...\")\n",
        "\n",
        "    # Ejecutar el flow\n",
        "    resultado = pipeline_taxi_simple()   # nombre de la funci√≥n del flow\n",
        "\n",
        "    print(\"\\nüìä RESULTADOS FINALES:\")\n",
        "    print(f\" Total registros: {resultado['total_registros']}\")\n",
        "    print(f\" Distancia promedio: {resultado['distancia_promedio']} millas\")\n",
        "    print(f\" Tarifa promedio: ${resultado['tarifa_promedio']}\")\n",
        "\n",
        "    print(\"\\nüèôÔ∏è Top 3 Boroughs:\")\n",
        "    for borough, count in resultado['boroughs'].items():  # clave del diccionario que contiene boroughs\n",
        "        print(f\" {borough}: {count} viajes\")"
      ],
      "metadata": {
        "id": "LTf5Ijs9siqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}